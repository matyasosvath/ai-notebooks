{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc51212b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Direct Preference Optimization: Your Language Model is Secretly a Reward Model\n",
    "# https://arxiv.org/abs/2305.18290"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "660a0cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "import os\n",
    "import tiktoken\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn.functional as F\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoModelForCausalLM\n",
    "\n",
    "from transformers.modeling_outputs import CausalLMOutputWithCrossAttentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8fca85f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"False\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6131b230",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mathcal{L}_{\\mathrm{DPO}}\\left(\\pi_\\theta ; \\pi_{\\mathrm{ref}}\\right)=-\\mathbb{E}_{\\left(x, y_w, y_l\\right) \\sim \\mathcal{D}}\\left[\\log \\sigma\\left(\\beta \\log \\frac{\\pi_\\theta\\left(y_w \\mid x\\right)}{\\pi_{\\mathrm{ref}}\\left(y_w \\mid x\\right)}-\\beta \\log \\frac{\\pi_\\theta\\left(y_l \\mid x\\right)}{\\pi_{\\mathrm{ref}}\\left(y_l \\mid x\\right)}\\right)\\right]\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f42f8eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d5b7a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"jondurbin/py-dpo-v0.1\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3ac069d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.train_test_split(test_size=0.1, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aed21cab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['prompt', 'chosen', 'rejected', 'id'],\n",
       "        num_rows: 8519\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['prompt', 'chosen', 'rejected', 'id'],\n",
       "        num_rows: 947\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c23e0943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: \n",
      "====================================\n",
      "What are some efficient algorithms in Python for finding the intersection between two sets of geographic coordinates within a given radius?\n",
      "\n",
      "\n",
      "Chosen: \n",
      "====================================\n",
      "One possible algorithm for finding the intersection between two sets of geographic coordinates within a given radius in Python is as follows:\n",
      "\n",
      "1. Define a function that calculates the great circle distance between two points on the Earth's surface. This can be done using the Haversine formula, which takes into account the Earth's radius and the latitude and longitude of the two points.\n",
      "\n",
      "2. Define a function that takes two sets of geographic coordinates (as lists of latitude and longitude pairs) and a radius as input, and returns the intersection between the two sets within the given radius. This can be done by looping over all pairs of points from the two sets and checking whether the great circle distance between them is less than the given radius. If so, add the pair to a list of intersecting points.\n",
      "\n",
      "3. Use this function to find the intersection between the two sets of coordinates.\n",
      "\n",
      "Here's an implementation of this algorithm in Python:\n",
      "\n",
      "```python\n",
      "import math\n",
      "\n",
      "def haversine(lat1, lon1, lat2, lon2):\n",
      "    # Convert latitude and longitude to radians\n",
      "    lat1, lon1, lat2, lon2 = map(math.radians, [lat1, lon1, lat2, lon2])\n",
      "\n",
      "    # Haversine formula\n",
      "    dlat = lat2 - lat1\n",
      "    dlon = lon2 - lon1\n",
      "    a = math.sin(dlat/2)**2 + math.cos(lat1) * math.cos(lat2) * math.sin(dlon/2)**2\n",
      "    c = 2 * math.asin(math.sqrt(a))\n",
      "    r = 6371 # Radius of the Earth in kilometers\n",
      "    return c * r\n",
      "\n",
      "def find_intersection(coords1, coords2, radius):\n",
      "    intersection = []\n",
      "    for coord1 in coords1:\n",
      "        for coord2 in coords2:\n",
      "            if haversine(coord1[0], coord1[1], coord2[0], coord2[1]) <= radius:\n",
      "                intersection.append((coord1, coord2))\n",
      "    return intersection\n",
      "\n",
      "# Example usage\n",
      "coords1 = [(40.748817, -73.985428), (37.774929, -122.419416), (51.507351, -0.127758)]\n",
      "coords2 = [(48.856614, 2.352222), (34.052234, -118.243685), (55.755826, 37.617299)]\n",
      "radius = 5000 # 5 km\n",
      "intersection = find_intersection(coords1, coords2, radius)\n",
      "print(intersection)\n",
      "```\n",
      "\n",
      "This implementation uses the Haversine formula to calculate the great circle distance between pairs of points on the Earth's surface, and checks whether the distance is less than or equal to the given radius. It returns a list of pairs of points that are within the given radius of each other.\n",
      "\n",
      "\n",
      "Rejected: \n",
      "====================================\n",
      "To find the intersection between two sets of geographic coordinates within a given radius, we can use the Haversine formula. The Haversine formula is a great tool for calculating the distance between two points on a sphere, which is what we need to do in this case.\n",
      "\n",
      "Here is an efficient algorithm in Python for finding the intersection between two sets of geographic coordinates within a given radius:\n",
      "\n",
      "```python\n",
      "import math\n",
      "\n",
      "def haversine(lat1, lon1, lat2, lon2):\n",
      "    # Convert latitude and longitude to radians\n",
      "    lat1, lon1, lat2, lon2 = map(math.radians, [lat1, lon1, lat2, lon2])\n",
      "\n",
      "    # Haversine formula\n",
      "    dlon = lon2 - lon1\n",
      "    dlat = lat2 - lat1\n",
      "    a = math.sin(dlat/2)**2 + math.cos(lat1) * math.cos(lat2) * math.sin(dlon/2)**2\n",
      "    c = 2 * math.asin(math.sqrt(a))\n",
      "    r = 6371 # Earth's radius in kilometers\n",
      "    return c * r\n",
      "\n",
      "def find_intersection(coordinates1, coordinates2, radius):\n",
      "    # Convert coordinates to latitude and longitude\n",
      "    coordinates1 = [(lat, lon) for lat, lon in coordinates1]\n",
      "    coordinates2 = [(lat, lon) for lat, lon in coordinates2]\n",
      "\n",
      "    # Calculate the distance between each pair of coordinates\n",
      "    distances = [haversine(lat1, lon1, lat2, lon2) for lat1, lon1, lat2, lon2 in zip(coordinates1, coordinates2, coordinates2, coordinates1)]\n",
      "\n",
      "    # Filter out coordinates that are within the given radius\n",
      "    filtered_coordinates = [coordinate for coordinate, distance in zip(coordinates1, distances) if distance <= radius]\n",
      "\n",
      "    return filtered_coordinates\n",
      "```\n",
      "\n",
      "To use this algorithm, you can call the `find_intersection` function with the two sets of coordinates and the desired radius. For example:\n",
      "\n",
      "```python\n",
      "coordinates1 = [(37.7749, -122.4194), (37.7749, -122.4194), (37.7749, -122.4194)]\n",
      "coordinates2 = [(37.7749, -122.4194), (37.7749, -122.4194), (37.7749, -122.4194)]\n",
      "radius = 1000 # 1 kilometer\n",
      "\n",
      "intersection = find_intersection(coordinates1, coordinates2, radius)\n",
      "print(intersection)\n",
      "```\n",
      "\n",
      "This will output the coordinates that are within 1 kilometer of each other.\n"
     ]
    }
   ],
   "source": [
    "print(\"Prompt: \")\n",
    "print(\"====================================\")\n",
    "print(dataset[\"train\"][0][\"prompt\"])\n",
    "print(\"\\n\\nChosen: \")\n",
    "print(\"====================================\")\n",
    "print(dataset[\"train\"][0][\"chosen\"])\n",
    "print(\"\\n\\nRejected: \")\n",
    "print(\"====================================\")\n",
    "print(dataset[\"train\"][0][\"rejected\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c1e9e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_input(entry):\n",
    "    instruction_text = (\n",
    "        f\"Below is an instruction that describes a task. \"\n",
    "        f\"Write a response that appropriately completes the request.\"\n",
    "        f\"\\n\\n### Instruction:\\n{entry['prompt']}\"\n",
    "    )\n",
    "    return instruction_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d6c3cc03",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tiktoken.get_encoding(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b0663b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_fn(entry: dict):\n",
    "\n",
    "    prompt = format_input(entry)\n",
    "    chosen_response = entry[\"chosen\"]\n",
    "    rejected_response = entry[\"rejected\"]\n",
    "\n",
    "    chosen_full_text = f\"{prompt}\\n\\n### Response:\\n{chosen_response}\"\n",
    "    rejected_full_text = f\"{prompt}\\n\\n### Response:\\n{rejected_response}\"\n",
    "\n",
    "    prompt_tokens = tokenizer.encode(chosen_full_text)\n",
    "    chosen_full_tokens = tokenizer.encode(chosen_full_text)\n",
    "    rejected_full_tokens = tokenizer.encode(rejected_full_text)\n",
    "\n",
    "    return { \"prompt\": prompt_tokens, \"chosen\": chosen_full_tokens, \"rejected\": rejected_full_tokens }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6b36f587",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = dataset[\"train\"].to_list()\n",
    "test_data = dataset[\"test\"].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "efc07f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreferenceDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer):\n",
    "        self.data = data\n",
    "\n",
    "        self.tokenized_data = []\n",
    "        for entry in data:\n",
    "            self.tokenized_data.append(tokenizer(entry))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.tokenized_data[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.tokenized_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b1534995",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = PreferenceDataset(train_data, tokenize_fn)\n",
    "test_dataset = PreferenceDataset(test_data, tokenize_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "404e3c22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: \n",
      "====================================\n",
      "[21106, 318, 281, 12064, 326, 8477, 257, 4876, 13, 19430, 257, 2882, 326, 20431, 32543, 262, 2581, 13, 198, 198, 21017, 46486, 25, 198, 2061, 389, 617, 6942, 16113, 287, 11361, 329, 4917, 262, 16246, 1022, 734, 5621, 286, 22987, 22715, 1626, 257, 1813, 16874, 30, 198, 198, 21017, 18261, 25, 198, 3198, 1744, 11862, 329, 4917, 262, 16246, 1022, 734, 5621, 286, 22987, 22715, 1626, 257, 1813, 16874, 287, 11361, 318, 355, 5679, 25, 198, 198, 16, 13, 2896, 500, 257, 2163, 326, 43707, 262, 1049, 9197, 5253, 1022, 734, 2173, 319, 262, 3668, 338, 4417, 13, 770, 460, 307, 1760, 1262, 262, 9398, 690, 500, 10451, 11, 543, 2753, 656, 1848, 262, 3668, 338, 16874, 290, 262, 32477, 290, 890, 3984, 286, 262, 734, 2173, 13, 198, 198, 17, 13, 2896, 500, 257, 2163, 326, 2753, 734, 5621, 286, 22987, 22715, 357, 292, 8341, 286, 32477, 290, 890, 3984, 14729, 8, 290, 257, 16874, 355, 5128, 11, 290, 5860, 262, 16246, 1022, 262, 734, 5621, 1626, 262, 1813, 16874, 13, 770, 460, 307, 1760, 416, 9052, 278, 625, 477, 14729, 286, 2173, 422, 262, 734, 5621, 290, 10627, 1771, 262, 1049, 9197, 5253, 1022, 606, 318, 1342, 621, 262, 1813, 16874, 13, 1002, 523, 11, 751, 262, 5166, 284, 257, 1351, 286, 36177, 278, 2173, 13, 198, 198, 18, 13, 5765, 428, 2163, 284, 1064, 262, 16246, 1022, 262, 734, 5621, 286, 22715, 13, 198, 198, 4342, 338, 281, 7822, 286, 428, 11862, 287, 11361, 25, 198, 198, 15506, 63, 29412, 198, 11748, 10688, 198, 198, 4299, 387, 690, 500, 7, 15460, 16, 11, 300, 261, 16, 11, 3042, 17, 11, 300, 261, 17, 2599, 198, 220, 220, 220, 1303, 38240, 32477, 290, 890, 3984, 284, 2511, 1547, 198, 220, 220, 220, 3042, 16, 11, 300, 261, 16, 11, 3042, 17, 11, 300, 261, 17, 796, 3975, 7, 11018, 13, 6335, 1547, 11, 685, 15460, 16, 11, 300, 261, 16, 11, 3042, 17, 11, 300, 261, 17, 12962, 628, 220, 220, 220, 1303, 9398, 690, 500, 10451, 198, 220, 220, 220, 288, 15460, 796, 3042, 17, 532, 3042, 16, 198, 220, 220, 220, 288, 14995, 796, 300, 261, 17, 532, 300, 261, 16, 198, 220, 220, 220, 257, 796, 10688, 13, 31369, 7, 67, 15460, 14, 17, 8, 1174, 17, 1343, 10688, 13, 6966, 7, 15460, 16, 8, 1635, 10688, 13, 6966, 7, 15460, 17, 8, 1635, 10688, 13, 31369, 7, 67, 14995, 14, 17, 8, 1174, 17, 198, 220, 220, 220, 269, 796, 362, 1635, 10688, 13, 47337, 7, 11018, 13, 31166, 17034, 7, 64, 4008, 198, 220, 220, 220, 374, 796, 718, 38056, 1303, 48838, 286, 262, 3668, 287, 18212, 198, 220, 220, 220, 1441, 269, 1635, 374, 198, 198, 4299, 1064, 62, 3849, 5458, 7, 1073, 3669, 16, 11, 763, 3669, 17, 11, 16874, 2599, 198, 220, 220, 220, 16246, 796, 17635, 198, 220, 220, 220, 329, 6349, 16, 287, 763, 3669, 16, 25, 198, 220, 220, 220, 220, 220, 220, 220, 329, 6349, 17, 287, 763, 3669, 17, 25, 198, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 611, 387, 690, 500, 7, 37652, 16, 58, 15, 4357, 6349, 16, 58, 16, 4357, 6349, 17, 58, 15, 4357, 6349, 17, 58, 16, 12962, 19841, 16874, 25, 198, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 16246, 13, 33295, 19510, 37652, 16, 11, 6349, 17, 4008, 198, 220, 220, 220, 1441, 16246, 198, 198, 2, 17934, 8748, 198, 1073, 3669, 16, 796, 47527, 1821, 13, 22, 33646, 1558, 11, 532, 4790, 13, 4089, 4051, 2078, 828, 357, 2718, 13, 3324, 2920, 1959, 11, 532, 18376, 13, 19, 22913, 1433, 828, 357, 4349, 13, 35378, 35273, 11, 532, 15, 13, 16799, 38569, 15437, 198, 1073, 3669, 17, 796, 47527, 2780, 13, 5332, 2791, 1415, 11, 362, 13, 2327, 1828, 1828, 828, 357, 2682, 13, 2713, 1828, 2682, 11, 532, 16817, 13, 1731, 2623, 5332, 828, 357, 2816, 13, 2425, 3365, 2075, 11, 5214, 13, 47941, 22579, 15437, 198, 42172, 796, 23336, 1303, 642, 10571, 198, 3849, 5458, 796, 1064, 62, 3849, 5458, 7, 1073, 3669, 16, 11, 763, 3669, 17, 11, 16874, 8, 198, 4798, 7, 3849, 5458, 8, 198, 15506, 63, 198, 198, 1212, 7822, 3544, 262, 9398, 690, 500, 10451, 284, 15284, 262, 1049, 9197, 5253, 1022, 14729, 286, 2173, 319, 262, 3668, 338, 4417, 11, 290, 8794, 1771, 262, 5253, 318, 1342, 621, 393, 4961, 284, 262, 1813, 16874, 13, 632, 5860, 257, 1351, 286, 14729, 286, 2173, 326, 389, 1626, 262, 1813, 16874, 286, 1123, 584, 13]\n",
      "\n",
      "Chosen: \n",
      "====================================\n",
      "[21106, 318, 281, 12064, 326, 8477, 257, 4876, 13, 19430, 257, 2882, 326, 20431, 32543, 262, 2581, 13, 198, 198, 21017, 46486, 25, 198, 2061, 389, 617, 6942, 16113, 287, 11361, 329, 4917, 262, 16246, 1022, 734, 5621, 286, 22987, 22715, 1626, 257, 1813, 16874, 30, 198, 198, 21017, 18261, 25, 198, 3198, 1744, 11862, 329, 4917, 262, 16246, 1022, 734, 5621, 286, 22987, 22715, 1626, 257, 1813, 16874, 287, 11361, 318, 355, 5679, 25, 198, 198, 16, 13, 2896, 500, 257, 2163, 326, 43707, 262, 1049, 9197, 5253, 1022, 734, 2173, 319, 262, 3668, 338, 4417, 13, 770, 460, 307, 1760, 1262, 262, 9398, 690, 500, 10451, 11, 543, 2753, 656, 1848, 262, 3668, 338, 16874, 290, 262, 32477, 290, 890, 3984, 286, 262, 734, 2173, 13, 198, 198, 17, 13, 2896, 500, 257, 2163, 326, 2753, 734, 5621, 286, 22987, 22715, 357, 292, 8341, 286, 32477, 290, 890, 3984, 14729, 8, 290, 257, 16874, 355, 5128, 11, 290, 5860, 262, 16246, 1022, 262, 734, 5621, 1626, 262, 1813, 16874, 13, 770, 460, 307, 1760, 416, 9052, 278, 625, 477, 14729, 286, 2173, 422, 262, 734, 5621, 290, 10627, 1771, 262, 1049, 9197, 5253, 1022, 606, 318, 1342, 621, 262, 1813, 16874, 13, 1002, 523, 11, 751, 262, 5166, 284, 257, 1351, 286, 36177, 278, 2173, 13, 198, 198, 18, 13, 5765, 428, 2163, 284, 1064, 262, 16246, 1022, 262, 734, 5621, 286, 22715, 13, 198, 198, 4342, 338, 281, 7822, 286, 428, 11862, 287, 11361, 25, 198, 198, 15506, 63, 29412, 198, 11748, 10688, 198, 198, 4299, 387, 690, 500, 7, 15460, 16, 11, 300, 261, 16, 11, 3042, 17, 11, 300, 261, 17, 2599, 198, 220, 220, 220, 1303, 38240, 32477, 290, 890, 3984, 284, 2511, 1547, 198, 220, 220, 220, 3042, 16, 11, 300, 261, 16, 11, 3042, 17, 11, 300, 261, 17, 796, 3975, 7, 11018, 13, 6335, 1547, 11, 685, 15460, 16, 11, 300, 261, 16, 11, 3042, 17, 11, 300, 261, 17, 12962, 628, 220, 220, 220, 1303, 9398, 690, 500, 10451, 198, 220, 220, 220, 288, 15460, 796, 3042, 17, 532, 3042, 16, 198, 220, 220, 220, 288, 14995, 796, 300, 261, 17, 532, 300, 261, 16, 198, 220, 220, 220, 257, 796, 10688, 13, 31369, 7, 67, 15460, 14, 17, 8, 1174, 17, 1343, 10688, 13, 6966, 7, 15460, 16, 8, 1635, 10688, 13, 6966, 7, 15460, 17, 8, 1635, 10688, 13, 31369, 7, 67, 14995, 14, 17, 8, 1174, 17, 198, 220, 220, 220, 269, 796, 362, 1635, 10688, 13, 47337, 7, 11018, 13, 31166, 17034, 7, 64, 4008, 198, 220, 220, 220, 374, 796, 718, 38056, 1303, 48838, 286, 262, 3668, 287, 18212, 198, 220, 220, 220, 1441, 269, 1635, 374, 198, 198, 4299, 1064, 62, 3849, 5458, 7, 1073, 3669, 16, 11, 763, 3669, 17, 11, 16874, 2599, 198, 220, 220, 220, 16246, 796, 17635, 198, 220, 220, 220, 329, 6349, 16, 287, 763, 3669, 16, 25, 198, 220, 220, 220, 220, 220, 220, 220, 329, 6349, 17, 287, 763, 3669, 17, 25, 198, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 611, 387, 690, 500, 7, 37652, 16, 58, 15, 4357, 6349, 16, 58, 16, 4357, 6349, 17, 58, 15, 4357, 6349, 17, 58, 16, 12962, 19841, 16874, 25, 198, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 16246, 13, 33295, 19510, 37652, 16, 11, 6349, 17, 4008, 198, 220, 220, 220, 1441, 16246, 198, 198, 2, 17934, 8748, 198, 1073, 3669, 16, 796, 47527, 1821, 13, 22, 33646, 1558, 11, 532, 4790, 13, 4089, 4051, 2078, 828, 357, 2718, 13, 3324, 2920, 1959, 11, 532, 18376, 13, 19, 22913, 1433, 828, 357, 4349, 13, 35378, 35273, 11, 532, 15, 13, 16799, 38569, 15437, 198, 1073, 3669, 17, 796, 47527, 2780, 13, 5332, 2791, 1415, 11, 362, 13, 2327, 1828, 1828, 828, 357, 2682, 13, 2713, 1828, 2682, 11, 532, 16817, 13, 1731, 2623, 5332, 828, 357, 2816, 13, 2425, 3365, 2075, 11, 5214, 13, 47941, 22579, 15437, 198, 42172, 796, 23336, 1303, 642, 10571, 198, 3849, 5458, 796, 1064, 62, 3849, 5458, 7, 1073, 3669, 16, 11, 763, 3669, 17, 11, 16874, 8, 198, 4798, 7, 3849, 5458, 8, 198, 15506, 63, 198, 198, 1212, 7822, 3544, 262, 9398, 690, 500, 10451, 284, 15284, 262, 1049, 9197, 5253, 1022, 14729, 286, 2173, 319, 262, 3668, 338, 4417, 11, 290, 8794, 1771, 262, 5253, 318, 1342, 621, 393, 4961, 284, 262, 1813, 16874, 13, 632, 5860, 257, 1351, 286, 14729, 286, 2173, 326, 389, 1626, 262, 1813, 16874, 286, 1123, 584, 13]\n",
      "\n",
      "Rejected: \n",
      "====================================\n",
      "[21106, 318, 281, 12064, 326, 8477, 257, 4876, 13, 19430, 257, 2882, 326, 20431, 32543, 262, 2581, 13, 198, 198, 21017, 46486, 25, 198, 2061, 389, 617, 6942, 16113, 287, 11361, 329, 4917, 262, 16246, 1022, 734, 5621, 286, 22987, 22715, 1626, 257, 1813, 16874, 30, 198, 198, 21017, 18261, 25, 198, 2514, 1064, 262, 16246, 1022, 734, 5621, 286, 22987, 22715, 1626, 257, 1813, 16874, 11, 356, 460, 779, 262, 9398, 690, 500, 10451, 13, 383, 9398, 690, 500, 10451, 318, 257, 1049, 2891, 329, 26019, 262, 5253, 1022, 734, 2173, 319, 257, 16558, 11, 543, 318, 644, 356, 761, 284, 466, 287, 428, 1339, 13, 198, 198, 4342, 318, 281, 6942, 11862, 287, 11361, 329, 4917, 262, 16246, 1022, 734, 5621, 286, 22987, 22715, 1626, 257, 1813, 16874, 25, 198, 198, 15506, 63, 29412, 198, 11748, 10688, 198, 198, 4299, 387, 690, 500, 7, 15460, 16, 11, 300, 261, 16, 11, 3042, 17, 11, 300, 261, 17, 2599, 198, 220, 220, 220, 1303, 38240, 32477, 290, 890, 3984, 284, 2511, 1547, 198, 220, 220, 220, 3042, 16, 11, 300, 261, 16, 11, 3042, 17, 11, 300, 261, 17, 796, 3975, 7, 11018, 13, 6335, 1547, 11, 685, 15460, 16, 11, 300, 261, 16, 11, 3042, 17, 11, 300, 261, 17, 12962, 628, 220, 220, 220, 1303, 9398, 690, 500, 10451, 198, 220, 220, 220, 288, 14995, 796, 300, 261, 17, 532, 300, 261, 16, 198, 220, 220, 220, 288, 15460, 796, 3042, 17, 532, 3042, 16, 198, 220, 220, 220, 257, 796, 10688, 13, 31369, 7, 67, 15460, 14, 17, 8, 1174, 17, 1343, 10688, 13, 6966, 7, 15460, 16, 8, 1635, 10688, 13, 6966, 7, 15460, 17, 8, 1635, 10688, 13, 31369, 7, 67, 14995, 14, 17, 8, 1174, 17, 198, 220, 220, 220, 269, 796, 362, 1635, 10688, 13, 47337, 7, 11018, 13, 31166, 17034, 7, 64, 4008, 198, 220, 220, 220, 374, 796, 718, 38056, 1303, 3668, 338, 16874, 287, 18212, 198, 220, 220, 220, 1441, 269, 1635, 374, 198, 198, 4299, 1064, 62, 3849, 5458, 7, 37652, 17540, 16, 11, 22715, 17, 11, 16874, 2599, 198, 220, 220, 220, 1303, 38240, 22715, 284, 32477, 290, 890, 3984, 198, 220, 220, 220, 22715, 16, 796, 47527, 15460, 11, 300, 261, 8, 329, 3042, 11, 300, 261, 287, 22715, 16, 60, 198, 220, 220, 220, 22715, 17, 796, 47527, 15460, 11, 300, 261, 8, 329, 3042, 11, 300, 261, 287, 22715, 17, 60, 628, 220, 220, 220, 1303, 27131, 378, 262, 5253, 1022, 1123, 5166, 286, 22715, 198, 220, 220, 220, 18868, 796, 685, 3099, 690, 500, 7, 15460, 16, 11, 300, 261, 16, 11, 3042, 17, 11, 300, 261, 17, 8, 329, 3042, 16, 11, 300, 261, 16, 11, 3042, 17, 11, 300, 261, 17, 287, 19974, 7, 37652, 17540, 16, 11, 22715, 17, 11, 22715, 17, 11, 22715, 16, 15437, 628, 220, 220, 220, 1303, 25853, 503, 22715, 326, 389, 1626, 262, 1813, 16874, 198, 220, 220, 220, 29083, 62, 37652, 17540, 796, 685, 37652, 4559, 329, 20435, 11, 5253, 287, 19974, 7, 37652, 17540, 16, 11, 18868, 8, 611, 5253, 19841, 16874, 60, 628, 220, 220, 220, 1441, 29083, 62, 37652, 17540, 198, 15506, 63, 198, 198, 2514, 779, 428, 11862, 11, 345, 460, 869, 262, 4600, 19796, 62, 3849, 5458, 63, 2163, 351, 262, 734, 5621, 286, 22715, 290, 262, 10348, 16874, 13, 1114, 1672, 25, 198, 198, 15506, 63, 29412, 198, 37652, 17540, 16, 796, 47527, 2718, 13, 3324, 2920, 11, 532, 18376, 13, 19, 22913, 828, 357, 2718, 13, 3324, 2920, 11, 532, 18376, 13, 19, 22913, 828, 357, 2718, 13, 3324, 2920, 11, 532, 18376, 13, 19, 22913, 15437, 198, 37652, 17540, 17, 796, 47527, 2718, 13, 3324, 2920, 11, 532, 18376, 13, 19, 22913, 828, 357, 2718, 13, 3324, 2920, 11, 532, 18376, 13, 19, 22913, 828, 357, 2718, 13, 3324, 2920, 11, 532, 18376, 13, 19, 22913, 15437, 198, 42172, 796, 8576, 1303, 352, 11866, 263, 198, 198, 3849, 5458, 796, 1064, 62, 3849, 5458, 7, 37652, 17540, 16, 11, 22715, 17, 11, 16874, 8, 198, 4798, 7, 3849, 5458, 8, 198, 15506, 63, 198, 198, 1212, 481, 5072, 262, 22715, 326, 389, 1626, 352, 11866, 263, 286, 1123, 584, 13]\n"
     ]
    }
   ],
   "source": [
    "print(\"Prompt: \")\n",
    "print(\"====================================\")\n",
    "print(train_dataset[0][\"prompt\"])\n",
    "print(\"\\nChosen: \")\n",
    "print(\"====================================\")\n",
    "print(train_dataset[0][\"chosen\"])\n",
    "print(\"\\nRejected: \")\n",
    "print(\"====================================\")\n",
    "print(train_dataset[0][\"rejected\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "29756971",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(\n",
    "    batch,\n",
    "    pad_token_id = 50256,\n",
    "    context_length = None,\n",
    "    mask_prompt_tokens = True,\n",
    "    device = \"cpu\",\n",
    "):\n",
    "\n",
    "    batch_data = {\n",
    "        \"prompt\": [],\n",
    "        \"chosen\": [],\n",
    "        \"rejected\": [],\n",
    "        \"rejected_mask\": [], # padding mask\n",
    "        \"chosen_mask\": [] # padding mask\n",
    "    }\n",
    "\n",
    "    # dynamic padding\n",
    "    max_length_common = 0\n",
    "    for key in [\"chosen\", \"rejected\"]:\n",
    "        current_max = max(len(item[key])+1 for item in batch)\n",
    "        max_length_common = max(max_length_common, current_max)\n",
    "\n",
    "    for item in batch:\n",
    "        prompt = torch.tensor(item[\"prompt\"])\n",
    "        batch_data[\"prompt\"].append(prompt)\n",
    "\n",
    "        for key in [\"chosen\", \"rejected\"]:\n",
    "\n",
    "            # adjust padding according to the common maximum length\n",
    "            sequence = item[key]\n",
    "            padded = sequence + [pad_token_id] * (max_length_common - len(sequence))\n",
    "            mask = torch.ones(len(padded)).bool()\n",
    "\n",
    "            # print(f\"Sequence {key}: {sequence}\")\n",
    "            # print(f\"Length: {len(sequence)}\")\n",
    "            # print(f\"Max Length: {max_length_common}\")\n",
    "            # print(f\"Padded: {padded}\")\n",
    "            # print(f\"Mask: {mask}\")\n",
    "\n",
    "            # set mask for padding tokens\n",
    "            mask[len(sequence):] = False\n",
    "\n",
    "            # print(f\"Mask after padding token: {mask}\")\n",
    "\n",
    "            # set mask for all prompt tokens to false\n",
    "            # +2 sets the 2 newline (\"\\n\") tokens before \"### Response\" to false\n",
    "            if mask_prompt_tokens:\n",
    "                mask[:prompt.shape[0]+2] = False\n",
    "                # print(f\"Mask prompt tokens size: {prompt.shape[0]+2}\")\n",
    "                # print(f\"Mask prompt tokens after: {mask}\")\n",
    "                # print(f\"Mask prompt tokens any true: {mask.any()}\")\n",
    "\n",
    "\n",
    "            batch_data[key].append(torch.tensor(padded))\n",
    "            batch_data[f\"{key}_mask\"].append(mask)\n",
    "\n",
    "    for key in [\"chosen\", \"rejected\", \"chosen_mask\", \"rejected_mask\"]:\n",
    "        # stack all sequences into a tensor for the given key\n",
    "        tensor_stack = torch.stack(batch_data[key])\n",
    "\n",
    "        # truncate to maximum sequence length\n",
    "        if context_length is not None:\n",
    "            tensor_stack = tensor_stack[:, :context_length]\n",
    "\n",
    "        batch_data[key] = tensor_stack.to(\"cpu\") # avoid RuntimeError: Cannot re-initialize CUDA in forked subprocess.\n",
    "\n",
    "    return batch_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "19baaf22",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_collate_fn = partial(\n",
    "    collate_fn,\n",
    "    device=device,\n",
    "    mask_prompt_tokens=False,\n",
    "    context_length=1024\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b7d4c24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, collate_fn=custom_collate_fn, num_workers=1)\n",
    "test_loader = DataLoader(test_dataset,batch_size=8, collate_fn=custom_collate_fn, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e249b964",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in train_loader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e9091629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "torch.Size([8, 1024]) torch.Size([8, 1024])\n",
      "torch.Size([8, 1024]) torch.Size([8, 1024])\n",
      "torch.Size([8, 1024]) torch.Size([8, 1024])\n",
      "torch.Size([8, 1024]) torch.Size([8, 1024])\n",
      "torch.Size([8, 1024]) torch.Size([8, 1024])\n",
      "torch.Size([8, 1024]) torch.Size([8, 1024])\n",
      "torch.Size([8, 1024]) torch.Size([8, 1024])\n",
      "torch.Size([8, 838]) torch.Size([8, 838])\n",
      "torch.Size([8, 1024]) torch.Size([8, 1024])\n",
      "torch.Size([8, 1024]) torch.Size([8, 1024])\n",
      "torch.Size([8, 1024]) torch.Size([8, 1024])\n",
      "torch.Size([8, 913]) torch.Size([8, 913])\n",
      "\n",
      "Test loader:\n",
      "torch.Size([8, 1024]) torch.Size([8, 1024])\n",
      "torch.Size([8, 840]) torch.Size([8, 840])\n",
      "torch.Size([8, 1012]) torch.Size([8, 1012])\n",
      "torch.Size([8, 1024]) torch.Size([8, 1024])\n",
      "torch.Size([8, 1024]) torch.Size([8, 1024])\n",
      "torch.Size([8, 966]) torch.Size([8, 966])\n",
      "torch.Size([8, 1024]) torch.Size([8, 1024])\n",
      "torch.Size([8, 1024]) torch.Size([8, 1024])\n",
      "torch.Size([8, 994]) torch.Size([8, 994])\n",
      "torch.Size([8, 781]) torch.Size([8, 781])\n",
      "torch.Size([8, 1024]) torch.Size([8, 1024])\n",
      "torch.Size([8, 1024]) torch.Size([8, 1024])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loader:\")\n",
    "for idx, batch in enumerate(train_loader):\n",
    "    print(\n",
    "        batch[\"chosen\"].shape,\n",
    "        batch[\"rejected\"].shape,\n",
    "    )\n",
    "    if idx>10:\n",
    "        break\n",
    "\n",
    "print(\"\\nTest loader:\")\n",
    "for idx, batch in enumerate(test_loader):\n",
    "    print(\n",
    "        batch[\"chosen\"].shape,\n",
    "        batch[\"rejected\"].shape,\n",
    "    )\n",
    "    if idx>10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deceb1e3",
   "metadata": {},
   "source": [
    "## DPO training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66fb1a00",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mathcal{L}_{\\mathrm{DPO}}\\left(\\pi_\\theta ; \\pi_{\\mathrm{ref}}\\right)=-\\mathbb{E}_{\\left(x, y_w, y_l\\right) \\sim \\mathcal{D}}\\left[\\log \\sigma\\left(\\beta \\log \\frac{\\pi_\\theta\\left(y_w \\mid x\\right)}{\\pi_{\\mathrm{ref}}\\left(y_w \\mid x\\right)}-\\beta \\log \\frac{\\pi_\\theta\\left(y_l \\mid x\\right)}{\\pi_{\\mathrm{ref}}\\left(y_l \\mid x\\right)}\\right)\\right]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e42aae2b",
   "metadata": {},
   "source": [
    "where,\n",
    "- $\\pi_\\theta$ policy model (LLM to optimize)\n",
    "- $ \\pi_{\\mathrm{ref}}$ reference model (original LLM before optimization)\n",
    "- $\\mathbb{E}$ is expected value\n",
    "- $\\sigma$ logistic sigmoid function\n",
    "- $\\beta$ hyperparameter to control the divergence between the $\\pi_{\\theta}$ and $\\pi_{ref}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "219da855",
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_model = AutoModelForCausalLM.from_pretrained(\"gpt2\")\n",
    "reference_model = AutoModelForCausalLM.from_pretrained(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4e4be53a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-11): 12 x GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2SdpaAttention(\n",
       "          (c_attn): Conv1D(nf=2304, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=768)\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D(nf=3072, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=3072)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy_model.to(device)\n",
    "reference_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3dae32df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_logprobs(\n",
    "    logits, # (batch_size, num_tokens, vocab_size)\n",
    "    labels, # (batch_size, num_tokens)\n",
    "    selection_mask=None # (batch_size, num_tokens)\n",
    "):\n",
    "\n",
    "    # print(f\"Labels: {labels}\")\n",
    "    # print(f\"Labels shape: {labels.shape}\")\n",
    "\n",
    "    # labels are the inputs shifted by one\n",
    "    #   i.e. the model predicts the next token in the sequence,\n",
    "    #   so the labels are the input tokens shifted to the left\n",
    "    #   and the first token is ignored (because there's no previous token to predict)\n",
    "    labels = labels[:, 1:].clone()\n",
    "\n",
    "    # adjust logits to match the labels num_tokens\n",
    "    #   i.e. truncate the logits by removing the last token's logits\n",
    "    #   because there's no corresponding target (label) to predict for the last token.\n",
    "    if isinstance(logits, CausalLMOutputWithCrossAttentions): # transformers returns CausalLMOutputWithCrossAttentions class, workaround to get logits\n",
    "        logits = logits.logits\n",
    "\n",
    "    # print(f\"Logits: {logits}\")\n",
    "    # print(f\"Logits shape: {logits.shape}\")\n",
    "\n",
    "    logits = logits[:, :-1, :]\n",
    "\n",
    "    log_probs = F.log_softmax(logits, dim=-1)\n",
    "\n",
    "    # select log probability the model assigned to the correct token at each position\n",
    "    selected_log_probs = torch.gather(\n",
    "        input=log_probs,\n",
    "        dim=-1,\n",
    "        index=labels.unsqueeze(-1)\n",
    "    ).squeeze(-1)\n",
    "\n",
    "    # print(\"Log probs:\", selected_log_probs)\n",
    "    # print(\"Log probs shape:\", selected_log_probs.shape)\n",
    "\n",
    "    if selection_mask is not None:\n",
    "        mask = selection_mask[:, 1:].clone()\n",
    "\n",
    "        # print(\"Mask:\", mask)\n",
    "        # print(\"Mask shape:\", mask.shape)\n",
    "\n",
    "        # apply the mask to filter out padding tokens\n",
    "        #    i.e. set the log probabilities of padding tokens to 0\n",
    "        selected_log_probs = selected_log_probs * mask\n",
    "\n",
    "        # print(\"selected log probs:\", selected_log_probs)\n",
    "        # print(\"selected log probs shape:\", selected_log_probs.shape)\n",
    "\n",
    "        # Calculate the average log probability excluding padding tokens\n",
    "        # This averages over the tokens, so the shape is (batch_size, num_tokens)\n",
    "        avg_log_prob = selected_log_probs.sum(-1) / mask.sum(-1) # divide by number of real tokens\n",
    "\n",
    "        return avg_log_prob\n",
    "\n",
    "    else:\n",
    "        return selected_log_probs.mean(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "30c084d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_dpo_loss(\n",
    "      model_chosen_logprobs,\n",
    "      model_rejected_logprobs,\n",
    "      reference_chosen_logprobs,\n",
    "      reference_rejected_logprobs,\n",
    "      beta=0.1,\n",
    "    ):\n",
    "\n",
    "    model_logratios = model_chosen_logprobs - model_rejected_logprobs\n",
    "    reference_logratios = reference_chosen_logprobs - reference_rejected_logprobs\n",
    "    logits = model_logratios - reference_logratios\n",
    "\n",
    "    losses = -F.logsigmoid(beta * logits)\n",
    "\n",
    "    # track progress during training\n",
    "    # reward ~ how much better the policy model is than the reference model\n",
    "    chosen_rewards = (model_chosen_logprobs - reference_chosen_logprobs).detach()\n",
    "    rejected_rewards = (model_rejected_logprobs - reference_rejected_logprobs).detach()\n",
    "\n",
    "    # .mean() to average over the samples in the batch\n",
    "    return losses.mean(), chosen_rewards.mean(), rejected_rewards.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6d4bcf8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_dpo_loss_batch(batch, policy_model, reference_model, beta):\n",
    "\n",
    "\n",
    "    batch = {k: v.to(device) if torch.is_tensor(v) else v for k, v in batch.items()}\n",
    "\n",
    "    # print(\"policy model device: \", policy_model.device)\n",
    "    # print(\"reference model device: \", reference_model.device)\n",
    "    # print(\"batch chose device: \", batch[\"chosen\"].device)\n",
    "    # print(\"batch rejected device: \", batch[\"rejected\"].device)\n",
    "\n",
    "    policy_chosen_log_probas = compute_logprobs(\n",
    "        logits=policy_model(batch[\"chosen\"]),\n",
    "        labels=batch[\"chosen\"],\n",
    "        selection_mask=batch[\"chosen_mask\"]\n",
    "    )\n",
    "    policy_rejected_log_probas = compute_logprobs(\n",
    "        logits=policy_model(batch[\"rejected\"]),\n",
    "        labels=batch[\"rejected\"],\n",
    "        selection_mask=batch[\"rejected_mask\"]\n",
    "    )\n",
    "\n",
    "    with torch.no_grad():\n",
    "        ref_chosen_log_probas = compute_logprobs(\n",
    "            logits=reference_model(batch[\"chosen\"]),\n",
    "            labels=batch[\"chosen\"],\n",
    "            selection_mask=batch[\"chosen_mask\"]\n",
    "        )\n",
    "        ref_rejected_log_probas = compute_logprobs(\n",
    "            logits=reference_model(batch[\"rejected\"]),\n",
    "            labels=batch[\"rejected\"],\n",
    "            selection_mask=batch[\"rejected_mask\"]\n",
    "        )\n",
    "    loss, chosen_rewards, rejected_rewards = compute_dpo_loss(\n",
    "        model_chosen_logprobs=policy_chosen_log_probas,\n",
    "        model_rejected_logprobs=policy_rejected_log_probas,\n",
    "        reference_chosen_logprobs=ref_chosen_log_probas,\n",
    "        reference_rejected_logprobs=ref_rejected_log_probas,\n",
    "        beta=beta\n",
    "    )\n",
    "    return loss, chosen_rewards, rejected_rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4b0c96ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor(0.6931, device='cuda:0'), tensor(0., device='cuda:0'), tensor(0., device='cuda:0'))\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    loss = compute_dpo_loss_batch(batch, policy_model, reference_model, beta=0.1)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "15620cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_dpo_loss_loader(data_loader, policy_model, reference_model, beta, num_batches=None):\n",
    "\n",
    "    total_loss, total_chosen_rewards, total_rejected_rewards = 0., 0., 0.\n",
    "\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        # Reduce the number of batches to match the total number of batches in the data loader\n",
    "        # if num_batches exceeds the number of batches in the data loader\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "\n",
    "    for i, batch in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss, chosen_rewards, rejected_rewards = compute_dpo_loss_batch(\n",
    "                batch=batch,\n",
    "                policy_model=policy_model,\n",
    "                reference_model=reference_model,\n",
    "                beta=beta\n",
    "            )\n",
    "            total_loss += loss.item()\n",
    "            total_chosen_rewards += chosen_rewards.item()\n",
    "            total_rejected_rewards += rejected_rewards.item()\n",
    "\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    # calculate average\n",
    "    total_loss /= num_batches\n",
    "    total_chosen_rewards /= num_batches\n",
    "    total_rejected_rewards /= num_batches\n",
    "\n",
    "    return total_loss, total_chosen_rewards, total_rejected_rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "daceed43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_dpo_loss_loader(policy_model, reference_model, train_loader, val_loader, beta, eval_iter):\n",
    "\n",
    "    policy_model.eval()\n",
    "    with torch.no_grad():\n",
    "\n",
    "        train_loss, train_chosen_rewards, train_rejected_rewards = compute_dpo_loss_loader(\n",
    "            data_loader=train_loader,\n",
    "            policy_model=policy_model,\n",
    "            reference_model=reference_model,\n",
    "            beta=beta,\n",
    "            num_batches=eval_iter\n",
    "        )\n",
    "\n",
    "        val_loss, val_chosen_rewards, val_rejected_rewards = compute_dpo_loss_loader(\n",
    "            data_loader=val_loader,\n",
    "            policy_model=policy_model,\n",
    "            reference_model=reference_model,\n",
    "            beta=beta,\n",
    "            num_batches=eval_iter\n",
    "        )\n",
    "\n",
    "    res = {\n",
    "        \"train_loss\": train_loss,\n",
    "        \"train_chosen_reward\": train_chosen_rewards,\n",
    "        \"train_rejected_reward\": train_rejected_rewards,\n",
    "        \"val_loss\": val_loss,\n",
    "        \"val_chosen_reward\": val_chosen_rewards,\n",
    "        \"val_rejected_reward\": val_rejected_rewards\n",
    "    }\n",
    "\n",
    "    policy_model.train()\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f5005198",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_dpo(\n",
    "    policy_model,\n",
    "    reference_model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    optimizer,\n",
    "    num_epochs,\n",
    "    beta,\n",
    "    eval_freq,\n",
    "    eval_iter\n",
    "):\n",
    "\n",
    "    tracking = {\n",
    "        \"train_losses\": [],\n",
    "        \"train_chosen_rewards\": [],\n",
    "        \"train_rejected_rewards\": [],\n",
    "        \"val_losses\": [],\n",
    "        \"val_chosen_rewards\": [],\n",
    "        \"val_rejected_rewards\": [],\n",
    "        \"tokens_seen\": []\n",
    "    }\n",
    "    tokens_seen, global_step = 0, -1\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        policy_model.train()\n",
    "\n",
    "        for batch_idx, batch in enumerate(train_loader):\n",
    "\n",
    "            optimizer.zero_grad()  # reset loss gradients from previous batch iteration\n",
    "\n",
    "            loss, chosen_rewards, rejected_rewards = compute_dpo_loss_batch(\n",
    "                batch=batch,\n",
    "                policy_model=policy_model,\n",
    "                reference_model=reference_model,\n",
    "                beta=beta\n",
    "            )\n",
    "\n",
    "            loss.backward()  # calculate loss gradients\n",
    "            optimizer.step()  # update model weights using loss gradients\n",
    "\n",
    "            tokens_seen += batch[\"chosen\"].numel()\n",
    "            global_step += 1\n",
    "\n",
    "            # evaluation step\n",
    "            if global_step % eval_freq == 0:\n",
    "                res = evaluate_dpo_loss_loader(\n",
    "                    policy_model=policy_model,\n",
    "                    reference_model=reference_model,\n",
    "                    train_loader=train_loader,\n",
    "                    val_loader=val_loader,\n",
    "                    beta=beta,\n",
    "                    eval_iter=eval_iter\n",
    "                )\n",
    "                tracking[\"train_losses\"].append(res[\"train_loss\"])\n",
    "                tracking[\"train_chosen_rewards\"].append(res[\"train_chosen_reward\"])\n",
    "                tracking[\"train_rejected_rewards\"].append(res[\"train_rejected_reward\"])\n",
    "                tracking[\"val_losses\"].append(res[\"val_loss\"])\n",
    "                tracking[\"val_chosen_rewards\"].append(res[\"val_chosen_reward\"])\n",
    "                tracking[\"val_rejected_rewards\"].append(res[\"val_rejected_reward\"])\n",
    "                tracking[\"tokens_seen\"].append(tokens_seen)\n",
    "\n",
    "                # rewared margin ~ how much more the policy model prefers the preferred answer\n",
    "                #                  compared to the rejected one, relative to the reference model.\n",
    "                train_reward_margin = res[\"train_chosen_reward\"] - res[\"train_rejected_reward\"]\n",
    "                val_reward_margin = res[\"val_chosen_reward\"] - res[\"val_rejected_reward\"]\n",
    "\n",
    "                print(\n",
    "                    f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
    "                    f\"Train loss {res['train_loss']:.3f}, Val loss {res['val_loss']:.3f}, \"\n",
    "                    f\"Train reward margins {train_reward_margin:.3f}, \"\n",
    "                    f\"Val reward margins {val_reward_margin:.3f}\"\n",
    "                )\n",
    "    return tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8d42d9d5",
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 96.00 MiB. GPU 0 has a total capacity of 10.90 GiB of which 2.12 MiB is free. Process 1101019 has 2.74 GiB memory in use. Including non-PyTorch memory, this process has 8.14 GiB memory in use. Of the allocated memory 7.89 GiB is allocated by PyTorch, and 92.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdamW(policy_model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5e-6\u001b[39m, weight_decay\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m)\n\u001b[1;32m      7\u001b[0m num_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m----> 8\u001b[0m tracking \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model_dpo\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpolicy_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpolicy_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreference_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreference_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_freq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\n\u001b[1;32m     18\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     21\u001b[0m execution_time_minutes \u001b[38;5;241m=\u001b[39m (end_time \u001b[38;5;241m-\u001b[39m start_time) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m60\u001b[39m\n",
      "Cell \u001b[0;32mIn[40], line 31\u001b[0m, in \u001b[0;36mtrain_model_dpo\u001b[0;34m(policy_model, reference_model, train_loader, val_loader, optimizer, num_epochs, beta, eval_freq, eval_iter)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader):\n\u001b[1;32m     29\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()  \u001b[38;5;66;03m# reset loss gradients from previous batch iteration\u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m     loss, chosen_rewards, rejected_rewards \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_dpo_loss_batch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpolicy_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpolicy_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreference_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreference_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()  \u001b[38;5;66;03m# calculate loss gradients\u001b[39;00m\n\u001b[1;32m     39\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()  \u001b[38;5;66;03m# update model weights using loss gradients\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[36], line 12\u001b[0m, in \u001b[0;36mcompute_dpo_loss_batch\u001b[0;34m(batch, policy_model, reference_model, beta)\u001b[0m\n\u001b[1;32m      4\u001b[0m batch \u001b[38;5;241m=\u001b[39m {k: v\u001b[38;5;241m.\u001b[39mto(device) \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mis_tensor(v) \u001b[38;5;28;01melse\u001b[39;00m v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m batch\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# print(\"policy model device: \", policy_model.device)\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# print(\"reference model device: \", reference_model.device)\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# print(\"batch chose device: \", batch[\"chosen\"].device)\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# print(\"batch rejected device: \", batch[\"rejected\"].device)\u001b[39;00m\n\u001b[1;32m     11\u001b[0m policy_chosen_log_probas \u001b[38;5;241m=\u001b[39m compute_logprobs(\n\u001b[0;32m---> 12\u001b[0m     logits\u001b[38;5;241m=\u001b[39m\u001b[43mpolicy_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mchosen\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m     13\u001b[0m     labels\u001b[38;5;241m=\u001b[39mbatch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchosen\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     14\u001b[0m     selection_mask\u001b[38;5;241m=\u001b[39mbatch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchosen_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     15\u001b[0m )\n\u001b[1;32m     16\u001b[0m policy_rejected_log_probas \u001b[38;5;241m=\u001b[39m compute_logprobs(\n\u001b[1;32m     17\u001b[0m     logits\u001b[38;5;241m=\u001b[39mpolicy_model(batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrejected\u001b[39m\u001b[38;5;124m\"\u001b[39m]),\n\u001b[1;32m     18\u001b[0m     labels\u001b[38;5;241m=\u001b[39mbatch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrejected\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     19\u001b[0m     selection_mask\u001b[38;5;241m=\u001b[39mbatch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrejected_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     20\u001b[0m )\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n",
      "File \u001b[0;32m~/ai-notebooks/venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ai-notebooks/venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/ai-notebooks/venv/lib/python3.8/site-packages/transformers/models/gpt2/modeling_gpt2.py:1271\u001b[0m, in \u001b[0;36mGPT2LMHeadModel.forward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1263\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1264\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\u001b[39;00m\n\u001b[1;32m   1265\u001b[0m \u001b[38;5;124;03m    Labels for language modeling. Note that the labels **are shifted** inside the model, i.e. you can set\u001b[39;00m\n\u001b[1;32m   1266\u001b[0m \u001b[38;5;124;03m    `labels = input_ids` Indices are selected in `[-100, 0, ..., config.vocab_size]` All labels set to `-100`\u001b[39;00m\n\u001b[1;32m   1267\u001b[0m \u001b[38;5;124;03m    are ignored (masked), the loss is only computed for labels in `[0, ..., config.vocab_size]`\u001b[39;00m\n\u001b[1;32m   1268\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1269\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m-> 1271\u001b[0m transformer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1272\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1274\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1275\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1276\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1277\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1278\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1279\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1280\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1281\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1282\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1283\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1284\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1285\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1286\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m transformer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1288\u001b[0m \u001b[38;5;66;03m# Set device for model parallelism\u001b[39;00m\n",
      "File \u001b[0;32m~/ai-notebooks/venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ai-notebooks/venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/ai-notebooks/venv/lib/python3.8/site-packages/transformers/models/gpt2/modeling_gpt2.py:1132\u001b[0m, in \u001b[0;36mGPT2Model.forward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1120\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m   1121\u001b[0m         block\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m   1122\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1129\u001b[0m         output_attentions,\n\u001b[1;32m   1130\u001b[0m     )\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1132\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1133\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1134\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_past\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer_past\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1135\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1136\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1137\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1138\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1139\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1140\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1141\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1143\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n",
      "File \u001b[0;32m~/ai-notebooks/venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ai-notebooks/venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/ai-notebooks/venv/lib/python3.8/site-packages/transformers/models/gpt2/modeling_gpt2.py:652\u001b[0m, in \u001b[0;36mGPT2Block.forward\u001b[0;34m(self, hidden_states, layer_past, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    650\u001b[0m residual \u001b[38;5;241m=\u001b[39m hidden_states\n\u001b[1;32m    651\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mln_2(hidden_states)\n\u001b[0;32m--> 652\u001b[0m feed_forward_hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmlp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    653\u001b[0m \u001b[38;5;66;03m# residual connection\u001b[39;00m\n\u001b[1;32m    654\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m feed_forward_hidden_states\n",
      "File \u001b[0;32m~/ai-notebooks/venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ai-notebooks/venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/ai-notebooks/venv/lib/python3.8/site-packages/transformers/models/gpt2/modeling_gpt2.py:575\u001b[0m, in \u001b[0;36mGPT2MLP.forward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    574\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_states: Optional[Tuple[torch\u001b[38;5;241m.\u001b[39mFloatTensor]]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mFloatTensor:\n\u001b[0;32m--> 575\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_fc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    576\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact(hidden_states)\n\u001b[1;32m    577\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mc_proj(hidden_states)\n",
      "File \u001b[0;32m~/ai-notebooks/venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ai-notebooks/venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/ai-notebooks/venv/lib/python3.8/site-packages/transformers/pytorch_utils.py:111\u001b[0m, in \u001b[0;36mConv1D.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m    110\u001b[0m     size_out \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39msize()[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m+\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnf,)\n\u001b[0;32m--> 111\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maddmm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    112\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mview(size_out)\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 96.00 MiB. GPU 0 has a total capacity of 10.90 GiB of which 2.12 MiB is free. Process 1101019 has 2.74 GiB memory in use. Including non-PyTorch memory, this process has 8.14 GiB memory in use. Of the allocated memory 7.89 GiB is allocated by PyTorch, and 92.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "optimizer = torch.optim.AdamW(policy_model.parameters(), lr=5e-6, weight_decay=0.01)\n",
    "\n",
    "num_epochs = 1\n",
    "tracking = train_model_dpo(\n",
    "    policy_model=policy_model,\n",
    "    reference_model=reference_model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=test_loader,\n",
    "    optimizer=optimizer,\n",
    "    num_epochs=num_epochs,\n",
    "    beta=0.5,\n",
    "    eval_freq=5,\n",
    "    eval_iter=5\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1efd7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses, label=\"loss\"):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "\n",
    "    # Plot training and validation loss against epochs\n",
    "    ax1.plot(epochs_seen, train_losses, label=f\"Training {label}\")\n",
    "    ax1.plot(epochs_seen, val_losses, linestyle=\"-.\", label=f\"Validation {label}\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(label.capitalize())\n",
    "    ax1.legend()\n",
    "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))  # only show integer labels on x-axis\n",
    "\n",
    "    # Create a second x-axis for tokens seen\n",
    "    ax2 = ax1.twiny()  # Create a second x-axis that shares the same y-axis\n",
    "    ax2.plot(tokens_seen, train_losses, alpha=0)  # Invisible plot for aligning ticks\n",
    "    ax2.set_xlabel(\"Tokens seen\")\n",
    "\n",
    "    fig.tight_layout()  # Adjust layout to make room\n",
    "    plt.savefig(f\"{label}-plot.pdf\")\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
