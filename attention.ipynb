{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hLo1MWPC5mGD"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "yDD_hlDo5thS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "nnYQ5k6R5zfB",
        "outputId": "0f7bcb4e-d9a3-4172-9d17-942ff5b99ff9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7d9dc279a390>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 8                      # b, b_sz\n",
        "context_len = 1024                  # seq_len, context_length, num_tokens, t, n_tokens\n",
        "d_model = 768                       # embed_dim, d_in, d_out, d\n",
        "n_heads = 6                         # h\n",
        "n_groups = 2                        # g\n",
        "head_dim = d_model // n_heads       # d_k, d_v"
      ],
      "metadata": {
        "id": "v13QB5gN51Kr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.randn((batch_size, context_len, d_model), device=device)"
      ],
      "metadata": {
        "id": "GhXfI5uO56Oz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Multi-Head Attention (MHA)\n",
        "\n",
        "Vaswani, Ashish, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, and Illia Polosukhin. “Attention Is All You Need.” arXiv, 2017. https://doi.org/10.48550/arXiv.1706.03762."
      ],
      "metadata": {
        "id": "HTpny5Ah6MOl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$$\n",
        "\\operatorname{Attention}(Q, K, V)=\\operatorname{softmax}\\left(\\frac{Q K^T}{\\sqrt{d_k}}\\right) V\n",
        "$$"
      ],
      "metadata": {
        "id": "yxWmmWd2Doai"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Head(nn.Module):\n",
        "    def __init__(self, d_model: int, d_out: int, context_length: int, attn_dropout: float = 0.0, qkv_bias: bool = False) -> None:\n",
        "        super().__init__()\n",
        "\n",
        "        self.key = nn.Linear(d_model, d_out, bias = qkv_bias)\n",
        "        self.query = nn.Linear(d_model, d_out, bias = qkv_bias)\n",
        "        self.value = nn.Linear(d_model, d_out, bias = qkv_bias)\n",
        "\n",
        "        # casual mask (another solution)\n",
        "        # self.register_buffer('mask', torch.triu(torch.ones(context_length, context_length)))\n",
        "\n",
        "        self.dropout = nn.Dropout(attn_dropout)\n",
        "\n",
        "    def forward(self, query, key, value, attn_mask = None, padding_mask = None) -> torch.Tensor:\n",
        "\n",
        "        # b, t, d_model = x.shape\n",
        "\n",
        "        q = self.query(query)   # (b, t, d_k)\n",
        "        k = self.key(key)       # (b, t, d_k)\n",
        "        v = self.value(value)   # (b, t, d_v)\n",
        "\n",
        "        # (b, t, t) = (b, t, d) @ (b, d, t)\n",
        "        attn_scores = q @ k.transpose(1, 2)\n",
        "\n",
        "        # casual mask (t, t)\n",
        "        if attn_mask is not None:\n",
        "            # attn_scores.masked_fill_(self.mask.bool()[:t, :t], -torch.inf)\n",
        "            attn_scores.masked_fill_(attn_mask, -torch.inf) # casual attention (set all true positions to -inf)\n",
        "\n",
        "        attn_weights = torch.softmax(attn_scores / k.shape[-1]**0.5, dim=-1)\n",
        "\n",
        "        attn_weights = self.dropout(attn_weights)\n",
        "\n",
        "        context_vec = attn_weights @ v\n",
        "\n",
        "        return context_vec"
      ],
      "metadata": {
        "id": "gvtEoU_J6OEZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "$$\n",
        "\\operatorname{MultiHead}(X_Q, X_K, X_V) = \\operatorname{Concat}\\left(\\operatorname{head}_1, \\ldots, \\operatorname{head}_{\\mathrm{h}}\\right) W^O\n",
        "$$\n"
      ],
      "metadata": {
        "id": "PKz8TwILDrTV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$$\n",
        "\\quad \\quad \\quad \\operatorname{head}_i = \\operatorname{Attention} \\left(X_Q W_i^Q, X_K W_i^K, X_V W_i^V \\right)\n",
        "$$"
      ],
      "metadata": {
        "id": "Y9Bqn9e28KRZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "where,\n",
        "- $W_i^Q \\in \\mathbb{R}^{d_{\\text {model }} \\times d_k}$,\n",
        "- $W_i^K \\in \\mathbb{R}^{d_{\\text {model }} \\times d_k}$,\n",
        "- $W_i^V \\in \\mathbb{R}^{d_{\\text {model }} \\times d_v}$,\n",
        "- $W^O \\in \\mathbb{R}^{h d_v \\times d_{\\text {model }}}$.\n",
        "\n",
        "For each of these we use $d_k = d_v = \\frac{d_{model}}{h}$."
      ],
      "metadata": {
        "id": "wL3PzE2k8KTb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, d_model: int, h: int, context_length: int, attn_dropout: float = 0.0, qkv_bias: bool = False):\n",
        "        super().__init__()\n",
        "\n",
        "        assert d_model % n_heads == 0, \"d_model is indivisible by n_heads\"\n",
        "\n",
        "        self.d_out = d_model // h # = d_k = d_v\n",
        "\n",
        "        self.heads = nn.ModuleList(\n",
        "            [ Head(d_model, self.d_out, context_length, attn_dropout, qkv_bias) for _ in range(h) ]\n",
        "        )\n",
        "        self.w_o = nn.Linear(n_heads * self.d_out, d_model) # out_proj\n",
        "\n",
        "    def forward(self, query, key, value, attn_mask, padding_mask = None):\n",
        "        out = torch.cat([head(query, key, value, attn_mask, padding_mask) for head in self.heads], dim=-1)\n",
        "        out = self.w_o(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "cqS9boi56OiA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mha = MultiHeadAttention(d_model, n_heads, context_len).to(device)"
      ],
      "metadata": {
        "id": "DjaANx9g6OkO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = mha(x, x, x, attn_mask=None)\n",
        "result.shape # (batch_size, num_tokens, d_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CHQLjB7y6Oms",
        "outputId": "407f4ca1-b193-4fdd-c3a8-a7c7254b41e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([8, 1024, 768])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### MHA with Combined QKV"
      ],
      "metadata": {
        "id": "VoN2OEdTEtmL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "\n",
        "    def __init__(self, d_model: int, h: int, dropout = 0.0, qkv_bias = False):\n",
        "        super().__init__()\n",
        "\n",
        "        assert d_model % h == 0, \"d_model is indivisible by h (number of heads)\"\n",
        "\n",
        "        self.h = h\n",
        "        self.d_model = d_model\n",
        "        self.d_out = d_model // h # d_v, d_k\n",
        "\n",
        "        self.qkv = nn.Linear(d_model, 3 * self.d_model, bias = qkv_bias)\n",
        "\n",
        "        self.proj = nn.Linear(h * self.d_out, d_model)\n",
        "\n",
        "\n",
        "    def forward(self, x: torch.Tensor):\n",
        "\n",
        "        b, t, d_model = x.shape\n",
        "\n",
        "        qkv = self.qkv(x) # (b, t, 3 * d_out)\n",
        "\n",
        "        qkv = qkv.view(b, t, 3, self.h, self.d_out)\n",
        "\n",
        "        qkv = qkv.permute(2, 0, 3, 1, 4) # (3, b, h, t, d_out)\n",
        "\n",
        "        queries, keys, values = qkv.unbind(0) # 3 x (b, h, t, d_out)\n",
        "\n",
        "        # (b, h, t, t) = (b, h, t, d_out) @ (b, h, d_out, t)\n",
        "        attn_scores = queries @ keys.transpose(-2, -1)\n",
        "\n",
        "        attn_weights = torch.softmax(attn_scores / math.sqrt(self.d_out), dim = -1)\n",
        "\n",
        "        # (b, h, t, d_out) = (b, h, t, t) @ (b, h, t, head_dim)\n",
        "        context_vec = attn_weights @ values\n",
        "\n",
        "        # (b, t, h, d_out) <- (b, h, t, d_out)\n",
        "        context_vec = context_vec.transpose(1, 2).contiguous()\n",
        "\n",
        "        context_vec = context_vec.contiguous().view(b, t, d_model)\n",
        "\n",
        "        context_vec = self.proj(context_vec)\n",
        "\n",
        "        return context_vec"
      ],
      "metadata": {
        "id": "IVkb_79S_7du"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mha = MultiHeadAttention(d_model, n_heads).to(device)"
      ],
      "metadata": {
        "id": "JBU-z5ZlB9Wd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mha(x).shape # (batch_size, num_tokens, d_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e_lAfeLj_7iw",
        "outputId": "60823ffa-cb34-4307-98a3-a7e0a0a8ea46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([8, 1024, 768])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### FlexAttention\n",
        "\n",
        "FlexAttention: The Flexibility of PyTorch with the Performance of FlashAttention https://pytorch.org/blog/flexattention/"
      ],
      "metadata": {
        "id": "uSd2sJluE0sp"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OLA2yOncE3oi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Multi-Query Attention (MQA)\n",
        "\n",
        "Shazeer, Noam. “Fast Transformer Decoding: One Write-Head Is All You Need.” arXiv, November 6, 2019. https://doi.org/10.48550/arXiv.1911.02150.\n"
      ],
      "metadata": {
        "id": "crfnr6gD6Otb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$$\n",
        "\\operatorname{Attention}(Q, K, V)=\\operatorname{softmax}\\left(\\frac{Q K^T}{\\sqrt{d_k}}\\right) V\n",
        "$$"
      ],
      "metadata": {
        "id": "asH7WE8-vouf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$$\n",
        "\\operatorname{MultiHead}(X_Q, X_K, X_V) = \\operatorname{Concat}\\left(\\operatorname{head}_1, \\ldots, \\operatorname{head}_{\\mathrm{h}}\\right) W^O\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\quad \\quad \\quad \\operatorname{head}_i = \\operatorname{Attention} \\left(X_Q W_i^Q, X_K W^K, X_V W^V \\right)\n",
        "$$\n",
        "\n",
        "where,\n",
        "- $W_i^Q \\in \\mathbb{R}^{d_{\\text {model }} \\times d_k}$,\n",
        "- $W^K \\in \\mathbb{R}^{d_{\\text {model }} \\times d_k}$,\n",
        "- $W^V \\in \\mathbb{R}^{d_{\\text {model }} \\times d_v}$,\n",
        "- $W^O \\in \\mathbb{R}^{h d_v \\times d_{\\text {model }}}$.\n",
        "\n",
        "For each of these we use $d_k = d_v = \\frac{d_{model}}{h}$."
      ],
      "metadata": {
        "id": "nfkO-QpWvp4R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiQueryAttention(nn.Module):\n",
        "\n",
        "    def __init__(self, d_model: int, h: int):\n",
        "        super().__init__()\n",
        "\n",
        "        assert d_model % h == 0, \"d_model is indivisible by h (number of heads)\"\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.h = h\n",
        "        self.d_k = self.d_v = d_model // h\n",
        "\n",
        "        self.q_proj = nn.Linear(d_model, h * self.d_k)\n",
        "        self.k_proj = nn.Linear(d_model, self.d_k)\n",
        "        self.v_proj = nn.Linear(d_model, self.d_v)\n",
        "\n",
        "        self.out_proj = nn.Linear(h * self.d_v, d_model)\n",
        "\n",
        "    def forward(self, x: torch.Tensor):\n",
        "\n",
        "        b, t, d_model = x.shape\n",
        "\n",
        "        q = self.q_proj(x).view(b, self.h, t, self.d_k)\n",
        "        k = self.k_proj(x).view(b, 1, t, self.d_k)\n",
        "        v = self.v_proj(x).view(b, 1, t, self.d_v)\n",
        "\n",
        "        k = k.repeat_interleave(self.h, dim=1)\n",
        "        v = v.repeat_interleave(self.h, dim=1)\n",
        "\n",
        "        # (b, h, t, t) = (b, h, t, d_k) @ (b, h, d_k, t)\n",
        "        attn_scores = torch.matmul(q, k.transpose(2, 3))\n",
        "\n",
        "        attn_weights = torch.softmax(attn_scores / math.sqrt(self.d_k), dim=-1)\n",
        "\n",
        "        # (b, h, t, d_v) = (b, h, t, t) @ (b, h, t, d_v)\n",
        "        # (b, t, h, d_v) <- (b, h, t, d_v)\n",
        "        context = torch.matmul(attn_weights, v).transpose(1, 2).contiguous()\n",
        "\n",
        "        context = context.view(b, t, self.d_model)\n",
        "\n",
        "        return self.out_proj(context)"
      ],
      "metadata": {
        "id": "Zjtag0R_6ZGU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mqa = MultiQueryAttention(d_model, n_heads).to(device)"
      ],
      "metadata": {
        "id": "KeBdW1zyGEH3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mqa(x).shape # (batch_size, num_tokens, d_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kGt9m6-N6Zkc",
        "outputId": "a96f1f2a-9b60-43ab-df2f-e5abdf300387"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([8, 1024, 768])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Grouped-query attention (GQA)\n",
        "\n",
        "Ainslie, Joshua, James Lee-Thorp, Michiel de Jong, Yury Zemlyanskiy, Federico Lebrón, and Sumit Sanghai. “GQA: Training Generalized Multi-Query Transformer Models from Multi-Head Checkpoints.” arXiv, December 23, 2023. https://doi.org/10.48550/arXiv.2305.13245.\n"
      ],
      "metadata": {
        "id": "sguUj-Ql6aAC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$$\n",
        "\\operatorname{Attention}(Q, K, V)=\\operatorname{softmax}\\left(\\frac{Q K^T}{\\sqrt{d_k}}\\right) V\n",
        "$$"
      ],
      "metadata": {
        "id": "tSf1s8Pkx5E-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$$\n",
        "\\operatorname{MultiHead}(X_Q, X_K, X_V) = \\operatorname{Concat}\\left(\\operatorname{head}_1, \\ldots, \\operatorname{head}_{\\mathrm{h}}\\right) W^O\n",
        "$$"
      ],
      "metadata": {
        "id": "Qy0rHwpnx5Hu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$$\n",
        "\\quad \\quad \\quad \\operatorname{head}_i = \\operatorname{Attention} \\left(X_Q W_i^Q, X_K W^K_{g(i)}, X_V W^V_{g(i)} \\right)\n",
        "$$"
      ],
      "metadata": {
        "id": "8PnLe_DAzcBQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Divide $i$ into groups of size $m$, that is:\n",
        "$$\n",
        "g(i) =\\left\\lfloor\\frac{i}{m}\\right\\rfloor\n",
        "$$\n",
        "\n",
        "$$\\therefore$$\n",
        "$$\n",
        "0 = g(0)=g(1)=\\cdots=g(m-1)\n",
        "$$\n",
        "$$\n",
        "1 = g(m)=g(m+1)=\\cdots=g(2m-1)\n",
        "$$\n",
        "$$\n",
        "\\vdots\n",
        "$$"
      ],
      "metadata": {
        "id": "8N992dSLz1xM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "where,\n",
        "- $W_i^Q \\in \\mathbb{R}^{d_{\\text {model }} \\times d_k}$,\n",
        "\n",
        "- $W_{g(i)}^K \\in \\mathbb{R}^{d_{\\text {model }} \\times d_k}$,\n",
        "- $W_{g(i)}^V \\in \\mathbb{R}^{d_{\\text {model }} \\times d_v}$,\n",
        "\n",
        "- $W^O \\in \\mathbb{R}^{h d_v \\times d_{\\text {model }}}$.\n",
        "\n",
        "For each of these we use $d_k = d_v = \\frac{d_{model}}{h}$."
      ],
      "metadata": {
        "id": "LvvAZ4RUzZU8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GroupedQueryAttention(nn.Module):\n",
        "    def __init__(self, d_model: int, h: int, n_groups: int, qkv_bias:bool=False):\n",
        "        super().__init__()\n",
        "\n",
        "        assert d_model % h == 0, \"d_model is indivisible by n_heads\"\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.h = h\n",
        "        self.d_k = self.d_v = d_model // h\n",
        "\n",
        "        self.g = n_groups\n",
        "        self.g_size = h // n_groups\n",
        "\n",
        "        self.q_proj = nn.Linear(d_model, self.h * self.d_k, bias = qkv_bias)\n",
        "        self.k_proj = nn.Linear(d_model, self.g * self.d_k, bias = qkv_bias)\n",
        "        self.v_proj = nn.Linear(d_model, self.g * self.d_v, bias = qkv_bias)\n",
        "\n",
        "        self.out_proj = nn.Linear(self.h * self.d_v, d_model)\n",
        "\n",
        "    def forward(self, x: torch.Tensor):\n",
        "\n",
        "        b, t, d  = x.shape\n",
        "\n",
        "        q = self.q_proj(x).view(b, self.h, t, self.d_k)\n",
        "        k = self.k_proj(x).view(b, self.g, t, self.d_k)\n",
        "        v = self.v_proj(x).view(b, self.g, t, self.d_v)\n",
        "\n",
        "        k = k.repeat_interleave(self.g_size, dim=1)\n",
        "        v = v.repeat_interleave(self.g_size, dim=1)\n",
        "\n",
        "        # (b, h, t, t) = (b,  h, t, d_k) x (b, h, d_k, t)\n",
        "        attn_scores = torch.matmul(q, k.transpose(2, 3)) / math.sqrt(self.d_k)\n",
        "\n",
        "        attn_weights = F.softmax(attn_scores, dim=-1)\n",
        "\n",
        "        # (b, t, h, d_v) <- (b, h, t, d_v) = (b, h, t, t) x (b, h, t, d_v)\n",
        "        context = torch.matmul(attn_weights, v).transpose(1, 2).contiguous()\n",
        "\n",
        "        context = context.view(batch_size, t, self.d_model)\n",
        "\n",
        "        return self.out_proj(context)"
      ],
      "metadata": {
        "id": "OOnr3eZE6bd5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gqa = GroupedQueryAttention(d_model, n_heads, 2).to(device)"
      ],
      "metadata": {
        "id": "I18fgWhZ6b44"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gqa(x).shape # (batch_size, num_tokens, d_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tct5MNBb6b7t",
        "outputId": "46e36517-d701-41e0-a2d9-c77e60022970"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([8, 1024, 768])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Multi-head Latent Attention (MLA)\n",
        "\n",
        "DeepSeek-AI, Aixin Liu, Bei Feng, Bin Wang, Bingxuan Wang, Bo Liu, Chenggang Zhao, et al. “DeepSeek-V2: A Strong, Economical, and Efficient Mixture-of-Experts Language Model.” arXiv, June 19, 2024. https://doi.org/10.48550/arXiv.2405.04434.\n"
      ],
      "metadata": {
        "id": "vbjmkJxI6cO0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let $n_h$ the number of attention heads and $i \\in\\left\\{1,2, \\ldots, n_h\\right\\}$, $d$ be the embedding dimension, $d_h$ be the dimension per head, and $\\mathbf{h}_t \\in \\mathbb{R}^d$ be the attention input of the $t$-th token at an attention layer."
      ],
      "metadata": {
        "id": "XMxVBdrxoXQR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$$\n",
        "\\begin{aligned}\n",
        "& {\\left[\\mathbf{q}_{t, 1} ; \\mathbf{q}_{t, 2} ; \\ldots ; \\mathbf{q}_{t, n_h}\\right]=\\mathbf{q}_t,} \\\\\n",
        "& {\\left[\\mathbf{k}_{t, 1} ; \\mathbf{k}_{t, 2} ; \\ldots ; \\mathbf{k}_{t, n_h}\\right]=\\mathbf{k}_t,} \\\\\n",
        "& {\\left[\\mathbf{v}_{t, 1} ; \\mathbf{v}_{t, 2} ; \\ldots ; \\mathbf{v}_{t, n_h}\\right]=\\mathbf{v}_t,}\n",
        "\\end{aligned}\n",
        "$$"
      ],
      "metadata": {
        "id": "eRrMRRUumdno"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$$\n",
        "\\mathbf{o}_{t, i}=\\sum_{j=1}^t \\operatorname{Softmax}_j\\left(\\frac{\\mathbf{q}_{t, i}^T \\mathbf{k}_{j, i}}{\\sqrt{d_h}}\\right) \\mathbf{v}_{j, i}\n",
        "$$"
      ],
      "metadata": {
        "id": "-mbxZGOXmdp-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$$\n",
        "\\mathbf{u}_t=W^O\\left[\\mathbf{o}_{t, 1} ; \\mathbf{o}_{t, 2} ; \\ldots ; \\mathbf{o}_{t, n_h}\\right],\n",
        "$$"
      ],
      "metadata": {
        "id": "WmyWpnLzmdr_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "where\n",
        "- $\\mathbf{q}_{t, i} \\in \\mathbb{R}^{d_h}$\n",
        "- $\\mathbf{k}_{t, i} \\in \\mathbb{R}^{d_h}$\n",
        "- $\\mathbf{v}_{t, i} \\in \\mathbb{R}^{d_h}$\n",
        "- $W^O \\in \\mathbb{R}^{d \\times d_h n_h}$"
      ],
      "metadata": {
        "id": "ZC_N95t5m_zh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The idea of MLA is the **low-rank joint compression** for keys and values to _reduce KV cache_ and for queries. That is, creating down-projection and up-projection matrices and sharing the down-projection matrix for key and values."
      ],
      "metadata": {
        "id": "oySuXOsqo6w0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$$\n",
        "\\begin{aligned}\n",
        "\\mathbf{c}_t^{K V} & =W^{D K V} \\mathbf{h}_t, \\\\\n",
        "\\mathbf{k}_t^C & =W^{U K} \\mathbf{c}_t^{K V}, \\\\\n",
        "\\mathbf{v}_t^C & =W^{U V} \\mathbf{c}_t^{K V},\n",
        "\\end{aligned}\n",
        "$$"
      ],
      "metadata": {
        "id": "8VYCa1TNo1hb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "where,\n",
        "- $\\mathbf{c}_t^{K V} \\in \\mathbb{R}^{d_c}$ and $d_c\\left(\\ll d_h n_h\\right)$\n",
        "- $W^{D K V} \\in \\mathbb{R}^{d_c \\times d}$\n",
        "- $W^{U K}, W^{U V} \\in \\mathbb{R}^{d_h n_h \\times d_c}$."
      ],
      "metadata": {
        "id": "wmikkXQ_p0Jm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$$\n",
        "\\mathbf{c}_t^Q=W^{D Q} \\mathbf{h}_t\n",
        "$$\n",
        "$$\n",
        "\\mathbf{q}_t^C=W^{U Q} \\mathbf{c}_t^Q\n",
        "$$"
      ],
      "metadata": {
        "id": "DgYuYdEApo1K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "where\n",
        "- $\\mathbf{c}_t^Q \\in \\mathbb{R}^{d_c^{\\prime}}$ and $d_c^{\\prime}\\left(\\ll d_h n_h\\right)$,\n",
        "- $W^{D Q} \\in \\mathbb{R}^{d_c^{\\prime} \\times d}$,\n",
        "- $W^{U Q} \\in \\mathbb{R}^{d_h n_h \\times d_c^{\\prime}}$"
      ],
      "metadata": {
        "id": "lyNNVoIvqMQM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "1gAqnAIiTE3k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadLatentAttention(nn.Module):\n",
        "    def __init__(self, d_model: int, n_h: int, d_cq: int = 12, d_c: int = 4):\n",
        "        super().__init__()\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.n_h = n_h          # n_heads\n",
        "        self.d_c = d_c          # d_c (<< d_h * n_h)\n",
        "        self.d_cq = d_cq        # d_c' (<< d_h * n_h)\n",
        "\n",
        "        self.d_h = d_model // n_heads\n",
        "\n",
        "        # down-projection matrices\n",
        "        self.w_dq = nn.Linear(d_model, d_cq)\n",
        "        self.w_dkv = nn.Linear(d_model, d_c)\n",
        "\n",
        "        # up-projection matrices\n",
        "        self.w_uq = nn.Linear(d_cq, n_h * self.d_h)\n",
        "        self.w_uk = nn.Linear(d_c, n_h * self.d_h)\n",
        "        self.w_uv = nn.Linear(d_c, n_h * self.d_h)\n",
        "\n",
        "        self.w_o = nn.Linear(n_heads * self.d_h, d_model) # out proj\n",
        "\n",
        "    def forward(self, x: torch.Tensor):\n",
        "\n",
        "        b, t, d_model = x.shape\n",
        "\n",
        "        # compression\n",
        "        c_q = self.w_dq(x)     # (b, t, d_c')\n",
        "        c_kv = self.w_dkv(x)   # (b, t, d_c)\n",
        "\n",
        "        # decompression\n",
        "        q_c = self.w_uq(c_q).view(b, self.n_h, t, self.d_h)\n",
        "        k_c = self.w_uk(c_kv).view(b, self.n_h, t, self.d_h)\n",
        "        v_c = self.w_uv(c_kv).view(b, self.n_h, t, self.d_h)\n",
        "\n",
        "        # (b, h, t, t) = (b, h, t, d_h) x (b, h, d_h, t)\n",
        "        attn_scores = torch.matmul(q_c, k_c.transpose(2, 3)) / math.sqrt(self.d_h)\n",
        "\n",
        "        attn_weight = torch.softmax(attn_scores, dim=-1)\n",
        "\n",
        "        # (b, t, h, d_h) <- (b, h, t, d_h) = (b, h, t, t) x (b, h, t, d_h)\n",
        "        context = torch.matmul(attn_weight, v_c).transpose(1,2).contiguous()\n",
        "\n",
        "        context = context.view(b, t, self.d_model)\n",
        "\n",
        "        return self.w_o(context)"
      ],
      "metadata": {
        "id": "GUcchmSTargI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mla = MultiHeadLatentAttention(d_model, n_heads, 2).to(device)"
      ],
      "metadata": {
        "id": "Q9mmaI4JbkN-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mla(x).shape # (batch_size, num_tokens, d_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ow6gf8tbrJy",
        "outputId": "6a36a6b9-ee94-4ab3-a498-ee17ac6c717d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([8, 1024, 768])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Speed comparison"
      ],
      "metadata": {
        "id": "k5BL6mirr6De"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "attention_fns = {\n",
        "    \"mha\": mha,\n",
        "    \"mqa\": mqa,\n",
        "    \"gqa\": gqa,\n",
        "    \"mla\": mla\n",
        "}"
      ],
      "metadata": {
        "id": "r-vX8ABjsZMJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def time_pytorch_function(func, *input, num_repeats=1_000):\n",
        "\n",
        "    start = torch.cuda.Event(enable_timing=True)\n",
        "    end = torch.cuda.Event(enable_timing=True)\n",
        "\n",
        "    for _ in range(5):\n",
        "        func(*input)\n",
        "    torch.cuda.synchronize()\n",
        "\n",
        "    times = []\n",
        "    for _ in range(num_repeats):\n",
        "        start.record()\n",
        "        func(*input)\n",
        "        end.record()\n",
        "        torch.cuda.synchronize()\n",
        "        times.append(start.elapsed_time(end))\n",
        "\n",
        "    return np.mean(times), np.std(times)"
      ],
      "metadata": {
        "id": "A6CmvZbkr7nO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stats = [time_pytorch_function(fn, x, num_repeats=100) for fn in attention_fns.values()]"
      ],
      "metadata": {
        "collapsed": true,
        "id": "2uwjPn6lsVkK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "execution_means = [stat[0] for stat in stats]\n",
        "execution_stds = [stat[1] for stat in stats]"
      ],
      "metadata": {
        "id": "_ixSzqpasWUC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_execution_times(functions, execution_means, execution_stds):\n",
        "\n",
        "    fig, ax = plt.subplots()\n",
        "    bars = ax.bar(functions.keys(), execution_means, yerr=execution_stds, capsize=5, error_kw={'ecolor': 'grey'})\n",
        "\n",
        "    plt.ylabel(\"Execution time (ms)\")\n",
        "    plt.xticks(rotation=45, ha=\"right\")\n",
        "\n",
        "    max_execution_time = max(execution_means)\n",
        "    upper_ylim = max_execution_time + 0.4 * max_execution_time\n",
        "    plt.ylim(0, upper_ylim)\n",
        "\n",
        "    for bar in bars:\n",
        "        yval = bar.get_height()\n",
        "        plt.text(bar.get_x() + bar.get_width()/2, yval + (0.05 * upper_ylim), round(yval, 2), ha=\"center\", va=\"bottom\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "LijMU8udsGug"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_execution_times(attention_fns, execution_means, execution_stds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "TqdDxYOmsSyy",
        "outputId": "3d2c52ca-141f-431c-a454-cb9b3a0336b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}