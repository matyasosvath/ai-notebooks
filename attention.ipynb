{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "hLo1MWPC5mGD"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "yDD_hlDo5thS"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "nnYQ5k6R5zfB",
        "outputId": "824ccf56-c085-48c4-ac90-6231e6881c30"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x78557840abf0>"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.manual_seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "v13QB5gN51Kr"
      },
      "outputs": [],
      "source": [
        "batch_size = 8                      # b, b_sz\n",
        "context_len = 1024                  # seq_len, context_length, num_tokens, t, n_tokens\n",
        "d_model = 768                       # embed_dim, d_in, d_out, d\n",
        "n_heads = 6                         # h\n",
        "n_groups = 2                        # g\n",
        "head_dim = d_model // n_heads       # d_k, d_v"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "GhXfI5uO56Oz"
      },
      "outputs": [],
      "source": [
        "x = torch.randn((batch_size, context_len, d_model), device=device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HTpny5Ah6MOl"
      },
      "source": [
        "# Multi-Head Attention (MHA)\n",
        "\n",
        "Vaswani, Ashish, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, and Illia Polosukhin. “Attention Is All You Need.” arXiv, 2017. https://doi.org/10.48550/arXiv.1706.03762."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yxWmmWd2Doai"
      },
      "source": [
        "$$\n",
        "\\operatorname{Attention}(Q, K, V)=\\operatorname{softmax}\\left(\\frac{Q K^T}{\\sqrt{d_k}}\\right) V\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "gvtEoU_J6OEZ"
      },
      "outputs": [],
      "source": [
        "class Head(nn.Module):\n",
        "    def __init__(self, d_model: int, d_out: int, context_length: int, attn_dropout: float = 0.0, qkv_bias: bool = False) -> None:\n",
        "        super().__init__()\n",
        "\n",
        "        self.key = nn.Linear(d_model, d_out, bias = qkv_bias)\n",
        "        self.query = nn.Linear(d_model, d_out, bias = qkv_bias)\n",
        "        self.value = nn.Linear(d_model, d_out, bias = qkv_bias)\n",
        "\n",
        "        # casual mask (another solution)\n",
        "        # self.register_buffer('mask', torch.triu(torch.ones(context_length, context_length)))\n",
        "\n",
        "        self.dropout = nn.Dropout(attn_dropout)\n",
        "\n",
        "    def forward(self, query, key, value, attn_mask = None, padding_mask = None) -> torch.Tensor:\n",
        "\n",
        "        # b, t, d_model = x.shape\n",
        "\n",
        "        q = self.query(query)   # (b, t, d_k)\n",
        "        k = self.key(key)       # (b, t, d_k)\n",
        "        v = self.value(value)   # (b, t, d_v)\n",
        "\n",
        "        # (b, t, t) = (b, t, d) @ (b, d, t)\n",
        "        attn_scores = q @ k.transpose(1, 2)\n",
        "\n",
        "        # casual mask (t, t)\n",
        "        if attn_mask is not None:\n",
        "            # attn_scores.masked_fill_(self.mask.bool()[:t, :t], -torch.inf)\n",
        "            attn_scores.masked_fill_(attn_mask, -torch.inf) # casual attention (set all true positions to -inf)\n",
        "\n",
        "        attn_weights = torch.softmax(attn_scores / k.shape[-1]**0.5, dim=-1)\n",
        "\n",
        "        attn_weights = self.dropout(attn_weights)\n",
        "\n",
        "        context_vec = attn_weights @ v\n",
        "\n",
        "        return context_vec"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PKz8TwILDrTV"
      },
      "source": [
        "$$\n",
        "\\operatorname{MultiHead}(X_Q, X_K, X_V) = \\operatorname{Concat}\\left(\\operatorname{head}_1, \\ldots, \\operatorname{head}_{\\mathrm{h}}\\right) W^O\n",
        "$$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y9Bqn9e28KRZ"
      },
      "source": [
        "$$\n",
        "\\quad \\quad \\quad \\operatorname{head}_i = \\operatorname{Attention} \\left(X_Q W_i^Q, X_K W_i^K, X_V W_i^V \\right)\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wL3PzE2k8KTb"
      },
      "source": [
        "where,\n",
        "- $W_i^Q \\in \\mathbb{R}^{d_{\\text {model }} \\times d_k}$,\n",
        "- $W_i^K \\in \\mathbb{R}^{d_{\\text {model }} \\times d_k}$,\n",
        "- $W_i^V \\in \\mathbb{R}^{d_{\\text {model }} \\times d_v}$,\n",
        "- $W^O \\in \\mathbb{R}^{h d_v \\times d_{\\text {model }}}$.\n",
        "\n",
        "For each of these we use $d_k = d_v = \\frac{d_{model}}{h}$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "cqS9boi56OiA"
      },
      "outputs": [],
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, d_model: int, h: int, context_length: int, attn_dropout: float = 0.0, qkv_bias: bool = False):\n",
        "        super().__init__()\n",
        "\n",
        "        assert d_model % n_heads == 0, \"d_model is indivisible by n_heads\"\n",
        "\n",
        "        self.d_out = d_model // h # = d_k = d_v\n",
        "\n",
        "        self.heads = nn.ModuleList(\n",
        "            [ Head(d_model, self.d_out, context_length, attn_dropout, qkv_bias) for _ in range(h) ]\n",
        "        )\n",
        "        self.w_o = nn.Linear(n_heads * self.d_out, d_model) # out_proj\n",
        "\n",
        "    def forward(self, query, key, value, attn_mask, padding_mask = None):\n",
        "        out = torch.cat([head(query, key, value, attn_mask, padding_mask) for head in self.heads], dim=-1)\n",
        "        out = self.w_o(out)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "DjaANx9g6OkO"
      },
      "outputs": [],
      "source": [
        "mha = MultiHeadAttention(d_model, n_heads, context_len).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CHQLjB7y6Oms",
        "outputId": "bd405fc5-83ab-48f6-a318-a4624f03d14b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([8, 1024, 768])"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result = mha(x, x, x, attn_mask=None)\n",
        "result.shape # (batch_size, num_tokens, d_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VoN2OEdTEtmL"
      },
      "source": [
        "### MHA with Combined QKV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "IVkb_79S_7du"
      },
      "outputs": [],
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "\n",
        "    def __init__(self, d_model: int, h: int, dropout = 0.0, qkv_bias = False):\n",
        "        super().__init__()\n",
        "\n",
        "        assert d_model % h == 0, \"d_model is indivisible by h (number of heads)\"\n",
        "\n",
        "        self.h = h\n",
        "        self.d_model = d_model\n",
        "        self.d_out = d_model // h # d_v, d_k\n",
        "\n",
        "        self.qkv = nn.Linear(d_model, 3 * self.d_model, bias = qkv_bias)\n",
        "\n",
        "        self.proj = nn.Linear(h * self.d_out, d_model)\n",
        "\n",
        "\n",
        "    def forward(self, x: torch.Tensor):\n",
        "\n",
        "        b, t, d_model = x.shape\n",
        "\n",
        "        qkv = self.qkv(x) # (b, t, 3 * d_out)\n",
        "\n",
        "        qkv = qkv.view(b, t, 3, self.h, self.d_out)\n",
        "\n",
        "        qkv = qkv.permute(2, 0, 3, 1, 4) # (3, b, h, t, d_out)\n",
        "\n",
        "        queries, keys, values = qkv.unbind(0) # 3 x (b, h, t, d_out)\n",
        "\n",
        "        # (b, h, t, t) = (b, h, t, d_out) @ (b, h, d_out, t)\n",
        "        attn_scores = queries @ keys.transpose(-2, -1)\n",
        "\n",
        "        attn_weights = torch.softmax(attn_scores / math.sqrt(self.d_out), dim = -1)\n",
        "\n",
        "        # (b, h, t, d_out) = (b, h, t, t) @ (b, h, t, head_dim)\n",
        "        context_vec = attn_weights @ values\n",
        "\n",
        "        # (b, t, h, d_out) <- (b, h, t, d_out)\n",
        "        context_vec = context_vec.transpose(1, 2).contiguous()\n",
        "\n",
        "        context_vec = context_vec.contiguous().view(b, t, d_model)\n",
        "\n",
        "        context_vec = self.proj(context_vec)\n",
        "\n",
        "        return context_vec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "JBU-z5ZlB9Wd"
      },
      "outputs": [],
      "source": [
        "mha = MultiHeadAttention(d_model, n_heads).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e_lAfeLj_7iw",
        "outputId": "6461a624-fc09-4c97-b2f3-fbaaca9ba7b4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([8, 1024, 768])"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mha(x).shape # (batch_size, num_tokens, d_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uSd2sJluE0sp"
      },
      "source": [
        "### FlexAttention\n",
        "\n",
        "FlexAttention: The Flexibility of PyTorch with the Performance of FlashAttention https://pytorch.org/blog/flexattention/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "OLA2yOncE3oi"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "crfnr6gD6Otb"
      },
      "source": [
        "# Multi-Query Attention (MQA)\n",
        "\n",
        "Shazeer, Noam. “Fast Transformer Decoding: One Write-Head Is All You Need.” arXiv, November 6, 2019. https://doi.org/10.48550/arXiv.1911.02150.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "asH7WE8-vouf"
      },
      "source": [
        "$$\n",
        "\\operatorname{Attention}(Q, K, V)=\\operatorname{softmax}\\left(\\frac{Q K^T}{\\sqrt{d_k}}\\right) V\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nfkO-QpWvp4R"
      },
      "source": [
        "$$\n",
        "\\operatorname{MultiHead}(X_Q, X_K, X_V) = \\operatorname{Concat}\\left(\\operatorname{head}_1, \\ldots, \\operatorname{head}_{\\mathrm{h}}\\right) W^O\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\quad \\quad \\quad \\operatorname{head}_i = \\operatorname{Attention} \\left(X_Q W_i^Q, X_K W^K, X_V W^V \\right)\n",
        "$$\n",
        "\n",
        "where,\n",
        "- $W_i^Q \\in \\mathbb{R}^{d_{\\text {model }} \\times d_k}$,\n",
        "- $W^K \\in \\mathbb{R}^{d_{\\text {model }} \\times d_k}$,\n",
        "- $W^V \\in \\mathbb{R}^{d_{\\text {model }} \\times d_v}$,\n",
        "- $W^O \\in \\mathbb{R}^{h d_v \\times d_{\\text {model }}}$.\n",
        "\n",
        "For each of these we use $d_k = d_v = \\frac{d_{model}}{h}$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Zjtag0R_6ZGU"
      },
      "outputs": [],
      "source": [
        "class MultiQueryAttention(nn.Module):\n",
        "\n",
        "    def __init__(self, d_model: int, h: int):\n",
        "        super().__init__()\n",
        "\n",
        "        assert d_model % h == 0, \"d_model is indivisible by h (number of heads)\"\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.h = h\n",
        "        self.d_k = self.d_v = d_model // h\n",
        "\n",
        "        self.q_proj = nn.Linear(d_model, h * self.d_k)\n",
        "        self.k_proj = nn.Linear(d_model, self.d_k)\n",
        "        self.v_proj = nn.Linear(d_model, self.d_v)\n",
        "\n",
        "        self.out_proj = nn.Linear(h * self.d_v, d_model)\n",
        "\n",
        "    def forward(self, x: torch.Tensor):\n",
        "\n",
        "        b, t, d_model = x.shape\n",
        "\n",
        "        q = self.q_proj(x).view(b, self.h, t, self.d_k)\n",
        "        k = self.k_proj(x).view(b, 1, t, self.d_k)\n",
        "        v = self.v_proj(x).view(b, 1, t, self.d_v)\n",
        "\n",
        "        k = k.repeat_interleave(self.h, dim=1)\n",
        "        v = v.repeat_interleave(self.h, dim=1)\n",
        "\n",
        "        # (b, h, t, t) = (b, h, t, d_k) @ (b, h, d_k, t)\n",
        "        attn_scores = torch.matmul(q, k.transpose(2, 3))\n",
        "\n",
        "        attn_weights = torch.softmax(attn_scores / math.sqrt(self.d_k), dim=-1)\n",
        "\n",
        "        # (b, h, t, d_v) = (b, h, t, t) @ (b, h, t, d_v)\n",
        "        # (b, t, h, d_v) <- (b, h, t, d_v)\n",
        "        context = torch.matmul(attn_weights, v).transpose(1, 2).contiguous()\n",
        "\n",
        "        context = context.view(b, t, self.d_model)\n",
        "\n",
        "        return self.out_proj(context)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "KeBdW1zyGEH3"
      },
      "outputs": [],
      "source": [
        "mqa = MultiQueryAttention(d_model, n_heads).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kGt9m6-N6Zkc",
        "outputId": "b75a702e-451b-48e6-9c75-6cee6da7fae3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([8, 1024, 768])"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mqa(x).shape # (batch_size, num_tokens, d_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sguUj-Ql6aAC"
      },
      "source": [
        "# Grouped-query attention (GQA)\n",
        "\n",
        "Ainslie, Joshua, James Lee-Thorp, Michiel de Jong, Yury Zemlyanskiy, Federico Lebrón, and Sumit Sanghai. “GQA: Training Generalized Multi-Query Transformer Models from Multi-Head Checkpoints.” arXiv, December 23, 2023. https://doi.org/10.48550/arXiv.2305.13245.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tSf1s8Pkx5E-"
      },
      "source": [
        "$$\n",
        "\\operatorname{Attention}(Q, K, V)=\\operatorname{softmax}\\left(\\frac{Q K^T}{\\sqrt{d_k}}\\right) V\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qy0rHwpnx5Hu"
      },
      "source": [
        "$$\n",
        "\\operatorname{MultiHead}(X_Q, X_K, X_V) = \\operatorname{Concat}\\left(\\operatorname{head}_1, \\ldots, \\operatorname{head}_{\\mathrm{h}}\\right) W^O\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8PnLe_DAzcBQ"
      },
      "source": [
        "$$\n",
        "\\quad \\quad \\quad \\operatorname{head}_i = \\operatorname{Attention} \\left(X_Q W_i^Q, X_K W^K_{g(i)}, X_V W^V_{g(i)} \\right)\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8N992dSLz1xM"
      },
      "source": [
        "Divide $i$ into groups of size $m$, that is:\n",
        "$$\n",
        "g(i) =\\left\\lfloor\\frac{i}{m}\\right\\rfloor\n",
        "$$\n",
        "\n",
        "$$\\therefore$$\n",
        "$$\n",
        "0 = g(0)=g(1)=\\cdots=g(m-1)\n",
        "$$\n",
        "$$\n",
        "1 = g(m)=g(m+1)=\\cdots=g(2m-1)\n",
        "$$\n",
        "$$\n",
        "\\vdots\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LvvAZ4RUzZU8"
      },
      "source": [
        "where,\n",
        "- $W_i^Q \\in \\mathbb{R}^{d_{\\text {model }} \\times d_k}$,\n",
        "\n",
        "- $W_{g(i)}^K \\in \\mathbb{R}^{d_{\\text {model }} \\times d_k}$,\n",
        "- $W_{g(i)}^V \\in \\mathbb{R}^{d_{\\text {model }} \\times d_v}$,\n",
        "\n",
        "- $W^O \\in \\mathbb{R}^{h d_v \\times d_{\\text {model }}}$.\n",
        "\n",
        "For each of these we use $d_k = d_v = \\frac{d_{model}}{h}$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "OOnr3eZE6bd5"
      },
      "outputs": [],
      "source": [
        "class GroupedQueryAttention(nn.Module):\n",
        "    def __init__(self, d_model: int, h: int, n_groups: int, qkv_bias:bool=False):\n",
        "        super().__init__()\n",
        "\n",
        "        assert d_model % h == 0, \"d_model is indivisible by n_heads\"\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.h = h\n",
        "        self.d_k = self.d_v = d_model // h\n",
        "\n",
        "        self.g = n_groups\n",
        "        self.g_size = h // n_groups\n",
        "\n",
        "        self.q_proj = nn.Linear(d_model, self.h * self.d_k, bias = qkv_bias)\n",
        "        self.k_proj = nn.Linear(d_model, self.g * self.d_k, bias = qkv_bias)\n",
        "        self.v_proj = nn.Linear(d_model, self.g * self.d_v, bias = qkv_bias)\n",
        "\n",
        "        self.out_proj = nn.Linear(self.h * self.d_v, d_model)\n",
        "\n",
        "    def forward(self, x: torch.Tensor):\n",
        "\n",
        "        b, t, d  = x.shape\n",
        "\n",
        "        q = self.q_proj(x).view(b, self.h, t, self.d_k)\n",
        "        k = self.k_proj(x).view(b, self.g, t, self.d_k)\n",
        "        v = self.v_proj(x).view(b, self.g, t, self.d_v)\n",
        "\n",
        "        k = k.repeat_interleave(self.g_size, dim=1)\n",
        "        v = v.repeat_interleave(self.g_size, dim=1)\n",
        "\n",
        "        # (b, h, t, t) = (b,  h, t, d_k) x (b, h, d_k, t)\n",
        "        attn_scores = torch.matmul(q, k.transpose(2, 3)) / math.sqrt(self.d_k)\n",
        "\n",
        "        attn_weights = F.softmax(attn_scores, dim=-1)\n",
        "\n",
        "        # (b, t, h, d_v) <- (b, h, t, d_v) = (b, h, t, t) x (b, h, t, d_v)\n",
        "        context = torch.matmul(attn_weights, v).transpose(1, 2).contiguous()\n",
        "\n",
        "        context = context.view(batch_size, t, self.d_model)\n",
        "\n",
        "        return self.out_proj(context)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "I18fgWhZ6b44"
      },
      "outputs": [],
      "source": [
        "gqa = GroupedQueryAttention(d_model, n_heads, 2).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tct5MNBb6b7t",
        "outputId": "0fcede3a-1ec2-48db-f4ae-4c19e737335e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([8, 1024, 768])"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "gqa(x).shape # (batch_size, num_tokens, d_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vbjmkJxI6cO0"
      },
      "source": [
        "# Multi-head Latent Attention (MLA)\n",
        "\n",
        "DeepSeek-AI, Aixin Liu, Bei Feng, Bin Wang, Bingxuan Wang, Bo Liu, Chenggang Zhao, et al. “DeepSeek-V2: A Strong, Economical, and Efficient Mixture-of-Experts Language Model.” arXiv, June 19, 2024. https://doi.org/10.48550/arXiv.2405.04434.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k5BL6mirr6De"
      },
      "source": [
        "# Speed comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "r-vX8ABjsZMJ"
      },
      "outputs": [],
      "source": [
        "attention_fns = {\n",
        "    \"mha\": mha,\n",
        "    \"mqa\": mqa,\n",
        "    \"gqa\": gqa\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "A6CmvZbkr7nO"
      },
      "outputs": [],
      "source": [
        "def time_pytorch_function(func, *input, num_repeats=1_000):\n",
        "\n",
        "    start = torch.cuda.Event(enable_timing=True)\n",
        "    end = torch.cuda.Event(enable_timing=True)\n",
        "\n",
        "    for _ in range(5):\n",
        "        func(*input)\n",
        "    torch.cuda.synchronize()\n",
        "\n",
        "    times = []\n",
        "    for _ in range(num_repeats):\n",
        "        start.record()\n",
        "        func(*input)\n",
        "        end.record()\n",
        "        torch.cuda.synchronize()\n",
        "        times.append(start.elapsed_time(end))\n",
        "\n",
        "    return np.mean(times), np.std(times)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "collapsed": true,
        "id": "2uwjPn6lsVkK"
      },
      "outputs": [],
      "source": [
        "stats = [time_pytorch_function(fn, x, num_repeats=10_000) for fn in attention_fns.values()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "_ixSzqpasWUC"
      },
      "outputs": [],
      "source": [
        "execution_means = [stat[0] for stat in stats]\n",
        "execution_stds = [stat[1] for stat in stats]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "LijMU8udsGug"
      },
      "outputs": [],
      "source": [
        "def plot_execution_times(functions, execution_means, execution_stds):\n",
        "\n",
        "    fig, ax = plt.subplots()\n",
        "    bars = ax.bar(functions.keys(), execution_means, yerr=execution_stds, capsize=5, error_kw={'ecolor': 'grey'})\n",
        "\n",
        "    plt.ylabel(\"Execution time (ms)\")\n",
        "    plt.xticks(rotation=45, ha=\"right\")\n",
        "\n",
        "    max_execution_time = max(execution_means)\n",
        "    upper_ylim = max_execution_time + 0.4 * max_execution_time\n",
        "    plt.ylim(0, upper_ylim)\n",
        "\n",
        "    for bar in bars:\n",
        "        yval = bar.get_height()\n",
        "        plt.text(bar.get_x() + bar.get_width()/2, yval + (0.05 * upper_ylim), round(yval, 2), ha=\"center\", va=\"bottom\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "TqdDxYOmsSyy",
        "outputId": "1fe126cc-5600-45f2-bcc9-e787e89a7b9a"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plot_execution_times(attention_fns, execution_means, execution_stds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RdpYIJfDPMuR"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
