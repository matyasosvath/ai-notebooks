{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "hLo1MWPC5mGD"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "yDD_hlDo5thS"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "nnYQ5k6R5zfB"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "v13QB5gN51Kr"
      },
      "outputs": [],
      "source": [
        "batch_size = 8                      # b, b_sz\n",
        "context_len = 1024                  # seq_len, context_length, num_tokens, t, n_tokens\n",
        "d_model = 768                       # embed_dim, d_in, d_out, d\n",
        "n_heads = 6                         # h\n",
        "n_groups = 2                        # g\n",
        "head_dim = d_model // n_heads       # d_k, d_v"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "GhXfI5uO56Oz"
      },
      "outputs": [],
      "source": [
        "x = torch.randn((batch_size, context_len, d_model), device=device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HTpny5Ah6MOl"
      },
      "source": [
        "# Többfejű Figyelem (Multi-Head Attention, MHA)\n",
        "\n",
        "Vaswani, Ashish, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, and Illia Polosukhin. “Attention Is All You Need.” arXiv, 2017. https://doi.org/10.48550/arXiv.1706.03762."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x5U8ZVMQmAu2"
      },
      "source": [
        "A figyelem mechanizmus lehetővé teszi a modell számára, hogy a rejtett állapotokból (hidden state) álló szekvencia minden pozíciója kölcsönhatásba lépjen ugyanabban a szekvenciában lévő többi pozícióval, ezáltal az egyes szekvenciákon belül képes megragadni a távolsági (és közeli) kontextust is.\n",
        "\n",
        "Legyen $d$ beágyazás dimenzió és $\\mathbf{h}_t \\in \\mathbb{R}^d$ a bemeneti szekvencia $t$-edik elemének beágyazása egy figyelem rétegnél. A figyelem mechanizmus a bemenetet először három eltérő súlyvektor segítségével három különböző reprezentációra, ún. lekérdezés-, kulcs- és értékvektorokra képezi le, de a gyakorlatban a számításokat mátrixokba rendezik a hatékonyság érdekében. A $\\mathbf{W}^Q, \\mathbf{W}^K \\in \\mathbb{R}^{d \\times d_k}$, $\\mathbf{W}^V \\in \\mathbb{R}^{d \\times d_v}$ súlymátrixok állítják elő a $\\mathbf{q}_t, \\mathbf{k}_t \\in \\mathbb{R}^{d_k}$ és $\\mathbf{v}_t \\in \\mathbb{R}^{d_v}$ reprezentációkat:\n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "& \\mathbf{q}_t=\\mathbf{W}^Q \\mathbf{h}_t, \\\\\n",
        "& \\mathbf{k}_t=\\mathbf{W}^K \\mathbf{h}_t, \\\\\n",
        "& \\mathbf{v}_t=\\mathbf{W}^V \\mathbf{h}_t,\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "A $\\mathbf{q}$ lekérdezés, ahonnan a figyelem irányul, mint a cél a figyelem mechanizmusban. A $\\mathbf{k}$ kulcs, amire a figyelem irányul, mint a forrás az egyszerű figyelem mechanizmus esetén. A $\\mathbf{v}$ érték az éppen generált kontextus. A képletben szereplő $q,k, v$ betűk az angol query, key, value szavak kezdőbetűi.\n",
        "\n",
        "Következőnek, a lekérdezés- és kulcs skalárszorzatát veszik és elosztják a $\\sqrt{d_k}$ skálázási faktorral a numerikus stabilitás érdekében. Ezután, softmax függvényt alkalmazva a figyelem súlyokat kapják meg, amik az értékkel kerülnek súlyozásra. Ezáltal a $t$-edik token reprezentációjának (vagy kódolt kimenetének) eredménye kiszámítható a figyelem mechanizmus alkalmazásával az alábbi módon:\n",
        "\n",
        "$$\n",
        "\\mathbf{o}_{t}= \\operatorname{softmax} \\left( \\frac{\\mathbf{q}_{t} \\mathbf{k}_{t}^T}{\\sqrt{d_k}}\\right) \\mathbf{v}_{t}\n",
        "$$\n",
        "\n",
        "A szekvencia tokenjeinek kódolt kimenetei egyszerre számíthatók, mivel a fenti egyenletek kifejezhetőek olyan mátrixműveletekkel, amelyek hatékony módon számíthatóak párhuzamos számításokra specializált, modern hardvereken. A fenti egyenletet \\textbf{skálázott skalárszorzat-alapú figyelem}nek (scaled dot-product attention) nevezzük.\n",
        "\n",
        "Megjegyzés. A $d$, $d_k$ és $d_v$ gyakran megegyezik."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "gvtEoU_J6OEZ"
      },
      "outputs": [],
      "source": [
        "class Head(nn.Module):\n",
        "    def __init__(self, d_model: int, d_out: int, attn_dropout: float = 0.1, qkv_bias: bool = False) -> None:\n",
        "        super().__init__()\n",
        "\n",
        "        self.key = nn.Linear(d_model, d_out, bias = qkv_bias)\n",
        "        self.query = nn.Linear(d_model, d_out, bias = qkv_bias)\n",
        "        self.value = nn.Linear(d_model, d_out, bias = qkv_bias)\n",
        "\n",
        "        self.dropout = nn.Dropout(attn_dropout)\n",
        "\n",
        "    def forward(self, query, key, value, attn_mask = None, padding_mask = None) -> torch.Tensor:\n",
        "\n",
        "        b, t, d_model = query.shape\n",
        "\n",
        "        q = self.query(query)   # (b, t, d_k)\n",
        "        k = self.key(key)       # (b, t, d_k)\n",
        "        v = self.value(value)   # (b, t, d_v)\n",
        "\n",
        "        # (b, t, t) = (b, t, d) @ (b, d, t)\n",
        "        attn_scores = q @ k.transpose(1, 2)\n",
        "\n",
        "        # figyelem és padding maszk összefűzése\n",
        "        if padding_mask is not None:\n",
        "            padding_mask = padding_mask.view(b, 1, t)\n",
        "            if attn_mask is None:\n",
        "                attn_mask = padding_mask\n",
        "            else:\n",
        "                attn_mask = attn_mask + padding_mask # := logikai és\n",
        "\n",
        "        if attn_mask is not None:\n",
        "            attn_scores.masked_fill_(attn_mask, -torch.inf)\n",
        "\n",
        "        attn_weights = torch.softmax(attn_scores / k.shape[-1]**0.5, dim=-1)\n",
        "        attn_weights = self.dropout(attn_weights)\n",
        "        context_vec = attn_weights @ v\n",
        "        return context_vec"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TQR43nnZmJVD"
      },
      "source": [
        "A figyelem függvény egyszeri alkalamzása helyett a szerzők előnyösnek találták, hogy a lekérdezéseket, kulcsokat és értékeket $h$ alkalommal, különböző tanulható lineáris leképezésekkel vetítsék le rendre $d_k$ és $d_v$ dimenziókra. Az így kapott projektált lekérdezések, kulcsok és értékek mindegyikén párhuzamosan kerül kiszámításra a figyelemfüggvény, amely \\(d_v\\) dimenziós kimeneteket eredményez. A kimeneteket konkatenálják és egy utolsó lineáris leképezést alkalmaznak, hogy az eredeti $d$ dimenziós kimenet álljon elő. Ezt a technikát többszörös vagy \\textbf{többfejű figyelem}nek (multi-head attention) nevezzük."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YZKmg-wumJXe"
      },
      "source": [
        "A többfejű figyelem lehetővé teszi, hogy a modell különböző pozíciókban a reprezentáció különböző altereiből származó információkra egyidejűleg \"figyeljen\", gazdagabb kontextuális információt megragadva. Egyetlen figyelemfej esetén az átlagolás ezt a képességet korlátozná, mivel az információk összemosódnak."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PKz8TwILDrTV"
      },
      "source": [
        "Formálisan, legyen $h$ a figyelemfejek száma és $d_h$ a figyelemfejek dimenziója. A fentebbi egyenletben szereplő tagok a következőképpen alakulnak: a $\\mathbf{q}_t, \\mathbf{k}_t, \\mathbf{v}_t \\in \\mathbb{R}^{d_h h}$ reprezentációk előállnak a $\\mathbf{W}^Q, \\mathbf{W}^K, \\mathbf{W}^V \\in \\mathbb{R}^{d_h h \\times d}$ súlymátrixokból. Azután, a $\\mathbf{q}_t, \\mathbf{k}_t, \\mathbf{v}_t$ vektorokat $h$ részre osztjuk a többfejű figyelem kiszámításához, minden egyes figyelemfejhez egy-egy lekérdezés, kulcs és érték tartozik. Minden figyelemfejre külön-külön alkalmazzuk a skálázott skalárszorzat-alapú figyelem függvényt, majd a kimeneteket konkatenáljuk és egy utolsó lineáris rétegen keresztül leképezzük az eredeti $d$ dimenzióra:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y9Bqn9e28KRZ"
      },
      "source": [
        "$$\n",
        "\\begin{aligned}\n",
        "& {\\left[\\mathbf{q}_{t, 1} ; \\mathbf{q}_{t, 2} ; \\ldots ; \\mathbf{q}_{t, h}\\right]=\\mathbf{q}_t,} \\\\\n",
        "& {\\left[\\mathbf{k}_{t, 1} ; \\mathbf{k}_{t, 2} ; \\ldots ; \\mathbf{k}_{t, h}\\right]=\\mathbf{k}_t,} \\\\\n",
        "& {\\left[\\mathbf{v}_{t, 1} ; \\mathbf{v}_{t, 2} ; \\ldots ; \\mathbf{v}_{t, h}\\right]=\\mathbf{v}_t,}\n",
        "\\end{aligned}\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wL3PzE2k8KTb"
      },
      "source": [
        "$$\n",
        "\\mathbf{o}_{t, i}=\\sum_{j=1}^t \\operatorname{Softmax}_j\\left(\\frac{\\mathbf{q}_{t, i}^{\\top} \\mathbf{k}_{j, i}}{\\sqrt{d_h}}\\right) \\mathbf{v}_{j, i},\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\mathbf{u}_t=\\mathbf{W}^O\\left[\\mathbf{o}_{t, 1} ; \\mathbf{o}_{t, 2} ; \\ldots ; \\mathbf{o}_{t, h}\\right].\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kzvau7ynmRiS"
      },
      "source": [
        "A szerzők a tanulmányban $h = 8$ párhuzamos figyelemréteget, azaz fejet alkalmaztak. Mindegyik fej esetében $d_k = d_v = d / h = 64$ dimenziót használtak. Mivel minden fej csökkentett dimenziójú térben működik, a teljes számítási költség megközelítőleg megegyezik az egyetlen fejjel végzett, teljes dimenziójú figyelem számítási költségével."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a2sp_tSLmTnV"
      },
      "source": [
        "A transzformer architektúra *háromféle módon alkalmazza a többfejű figyelmet*.\n",
        "\n",
        "Először, a \"kódoló-dekódoló figyelem\" rétegekben a lekérdezés a dekóder előző rétegéből, míg a kulcs és az érték a kódoló kimenetéből származik. Ez lehetővé teszi, hogy a dekódoló minden pozíciója a bemeneti szekvencia összes pozícióját számításba vegye.\n",
        "\n",
        "Másodszor, a kódolóban a figyelem rétegekben a kulcsok, az értékek és a lekérdezések mind ugyanabból a forrásból származnak, azaz a kódoló előző rétegének kimenetéből. Ezt **önfigyelem**nek (self-attention) nevezzük. Ezáltal a kódoló minden pozíciója képes a kódoló előző rétegének bármely pozíciójára figyelni.\n",
        "\n",
        "Harmadszor, a dekódoló önfigyelem rétegei lehetővé teszik, hogy a dekódolóban minden pozíció észrevegye a korábbi, illetve az aktuális pozícióit. Azonban ebben az esetben meg kell akadályozni az információ balról jobbra történő áramlását, hogy az adott token ne függjön az utána következő tokenektől és csak az előtte lévő tokeneket tudja számításba venni, ezáltal megőrizve az autoregresszív tulajdonságot. A skálázott skalárszorzat-alapú figyelem során ez úgy kerül megvalósításra, hogy softmax függvény bemeneténél a jövőbeli pozícióknak megfelelő értékeket $-\\infty$-re állítjuk, aminek hatására a softmax kimenetében ezek nulla értéket vesznek fel, és így nem befolyásolják figyelem számítást. Ezt a módszert **maszkolás**nak (masking), illetve **kauzális maszk**nak (causal mask) is szokták nevezni és kritikus a nyelvi modellek esetében ahol a következő tokent a korábbi tokenek segítségével generáljuk. Az önfigyelem mechanizmus kauzális maszkolással kiegészített változatát **kauzális figyelem**nek (causal attention) is nevezik."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "cqS9boi56OiA"
      },
      "outputs": [],
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, d_model: int, h: int, attn_dropout: float = 0.1, qkv_bias: bool = False):\n",
        "        super().__init__()\n",
        "\n",
        "        assert d_model % h == 0, \"d_model is indivisible by h (n_heads)\"\n",
        "\n",
        "        self.d_out = d_model // h # = d_k = d_v\n",
        "\n",
        "        self.heads = nn.ModuleList(\n",
        "            [ Head(d_model, self.d_out, attn_dropout, qkv_bias) for _ in range(h) ]\n",
        "        )\n",
        "        self.w_o = nn.Linear(h * self.d_out, d_model) # out_proj\n",
        "\n",
        "    def forward(self, query, key, value, attn_mask = None, padding_mask = None):\n",
        "        out = torch.cat([head(query, key, value, attn_mask, padding_mask) for head in self.heads], dim=-1)\n",
        "        out = self.w_o(out)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "DjaANx9g6OkO"
      },
      "outputs": [],
      "source": [
        "mha = MultiHeadAttention(d_model, n_heads).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CHQLjB7y6Oms",
        "outputId": "aba45f37-6638-433c-e42c-ba42292760db"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([8, 1024, 768])"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result = mha(x, x, x, attn_mask=None)\n",
        "result.shape # (batch-méret, szekvencia hossz, beágyazás méret)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VoN2OEdTEtmL"
      },
      "source": [
        "### MHA kombinált QKV mátrixokkal (MHA with Combined QKV)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "IVkb_79S_7du"
      },
      "outputs": [],
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "\n",
        "    def __init__(self, d_model: int, h: int, dropout = 0.0, qkv_bias = False):\n",
        "        super().__init__()\n",
        "\n",
        "        assert d_model % h == 0, \"d_model is indivisible by h (number of heads)\"\n",
        "\n",
        "        self.h = h\n",
        "        self.d_model = d_model\n",
        "        self.d_out = d_model // h # d_v, d_k\n",
        "\n",
        "        self.qkv = nn.Linear(d_model, 3 * self.d_model, bias = qkv_bias)\n",
        "\n",
        "        self.proj = nn.Linear(h * self.d_out, d_model)\n",
        "\n",
        "\n",
        "    def forward(self, x: torch.Tensor):\n",
        "\n",
        "        b, t, d_model = x.shape\n",
        "\n",
        "        qkv = self.qkv(x) # (b, t, 3 * d_out)\n",
        "\n",
        "        qkv = qkv.view(b, t, 3, self.h, self.d_out)\n",
        "\n",
        "        qkv = qkv.permute(2, 0, 3, 1, 4) # (3, b, h, t, d_out)\n",
        "\n",
        "        queries, keys, values = qkv.unbind(0) # 3 x (b, h, t, d_out)\n",
        "\n",
        "        # (b, h, t, t) = (b, h, t, d_out) @ (b, h, d_out, t)\n",
        "        attn_scores = queries @ keys.transpose(-2, -1)\n",
        "\n",
        "        attn_weights = torch.softmax(attn_scores / math.sqrt(self.d_out), dim = -1)\n",
        "\n",
        "        # (b, h, t, d_out) = (b, h, t, t) @ (b, h, t, head_dim)\n",
        "        context_vec = attn_weights @ values\n",
        "\n",
        "        # (b, t, h, d_out) <- (b, h, t, d_out)\n",
        "        context_vec = context_vec.transpose(1, 2).contiguous()\n",
        "\n",
        "        context_vec = context_vec.contiguous().view(b, t, d_model)\n",
        "\n",
        "        context_vec = self.proj(context_vec)\n",
        "\n",
        "        return context_vec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "JBU-z5ZlB9Wd"
      },
      "outputs": [],
      "source": [
        "mha = MultiHeadAttention(d_model, n_heads).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e_lAfeLj_7iw",
        "outputId": "d78a7563-faeb-42d2-e2ca-c0e9cc549a64"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([8, 1024, 768])"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mha(x).shape # (batch-méret, szekvencia hossz, beágyazás méret)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "crfnr6gD6Otb"
      },
      "source": [
        "# Multi-lekérdezéses figyelem (Multi-Query Attention, MQA)\n",
        "\n",
        "Shazeer, Noam. “Fast Transformer Decoding: One Write-Head Is All You Need.” arXiv, November 6, 2019. https://doi.org/10.48550/arXiv.1911.02150.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JeoktUl5ix6Q"
      },
      "source": [
        "A több vagy multi-lekérdezéses figyelem (multi-query attention, MQA) Shazeer Noam által javasolt változat, amelyben minden figyelemfejhez külön lekérdezés ( $\\mathrm{Q}_i$ ) tartozik, míg a kulcs ($\\mathrm{K}$) és érték ($\\mathrm{V}$) mátrixok közösek az összes fej számára. Ez jelentősen csökkenti a modell paramétereinek számát és a memóriahasználatot, miközben a modell teljesítményének csökkenése minimális. A MQA különösen előnyös nagy nyelvi modellek esetében, ahol a memória korlátozott."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ri-qr4MRix8h"
      },
      "source": [
        "Legyen $\\mathbf{X} \\in \\mathbb{R}^{t \\times d}$ a bemeneti szekvencia beágyazásainak mátrixa, ahol $t$ a szekvencia hossza és $d$ a beágyazás dimenziója, illetve $h$ a figyelemfejek száma. Az MQA a következőképpen definiálható:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "asH7WE8-vouf"
      },
      "source": [
        "$$\n",
        "\\begin{array}{r}\n",
        "\\text { MultiFej }\\left(\\mathbf{X}_Q, \\mathbf{X}_K, \\mathbf{X}_V\\right)=\\text { Konkat }\\left(\\mathrm{fej}_1, \\ldots, \\mathrm{fej}_{\\mathrm{h}}\\right) \\mathbf{W}^O \\\\\n",
        "\\mathrm{fej}_i=\\text { Figyelem }\\left(\\mathbf{X}_Q \\mathbf{W}_i^Q, \\mathbf{X}_K \\mathbf{W}^K, \\mathbf{X}_V \\mathbf{W}^V\\right) .\n",
        "\\end{array}\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "og60VbRjjLSg"
      },
      "source": [
        "A $\\mathbf{W}_i^Q \\in \\mathbb{R}^{d \\times d_k}$ az $i$-edik fej lekérdezéséhez tartozó súlymátrix, $\\mathbf{W}^K \\in \\mathbb{R}^{d \\times d_k}$ a kulcshoz, $\\mathbf{W}^V \\in \\mathbb{R}^{d \\times d_v}$ az értékhez, illetve $\\mathbf{W}^O \\in \\mathbb{R}^{h d_v \\times d}$ a kimeneti leképezéshez használt mátrix. Mindegyik figyelemfej esetén $d_k=d_v=\\frac{d}{h}$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Zjtag0R_6ZGU"
      },
      "outputs": [],
      "source": [
        "class MultiQueryAttention(nn.Module):\n",
        "\n",
        "    def __init__(self, d_model: int, h: int):\n",
        "        super().__init__()\n",
        "\n",
        "        assert d_model % h == 0, \"d_model is indivisible by h (number of heads)\"\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.h = h\n",
        "        self.d_k = self.d_v = d_model // h\n",
        "\n",
        "        self.q_proj = nn.Linear(d_model, h * self.d_k)\n",
        "        self.k_proj = nn.Linear(d_model, self.d_k)\n",
        "        self.v_proj = nn.Linear(d_model, self.d_v)\n",
        "\n",
        "        self.out_proj = nn.Linear(h * self.d_v, d_model)\n",
        "\n",
        "    def forward(self, x: torch.Tensor):\n",
        "\n",
        "        b, t, d_model = x.shape\n",
        "\n",
        "        q = self.q_proj(x).view(b, self.h, t, self.d_k)\n",
        "        k = self.k_proj(x).view(b, 1, t, self.d_k)\n",
        "        v = self.v_proj(x).view(b, 1, t, self.d_v)\n",
        "\n",
        "        k = k.repeat_interleave(self.h, dim=1)\n",
        "        v = v.repeat_interleave(self.h, dim=1)\n",
        "\n",
        "        # (b, h, t, t) = (b, h, t, d_k) @ (b, h, d_k, t)\n",
        "        attn_scores = torch.matmul(q, k.transpose(2, 3))\n",
        "\n",
        "        attn_weights = torch.softmax(attn_scores / math.sqrt(self.d_k), dim=-1)\n",
        "\n",
        "        # (b, h, t, d_v) = (b, h, t, t) @ (b, h, t, d_v)\n",
        "        # (b, t, h, d_v) <- (b, h, t, d_v)\n",
        "        context = torch.matmul(attn_weights, v).transpose(1, 2).contiguous()\n",
        "\n",
        "        context = context.view(b, t, self.d_model)\n",
        "\n",
        "        return self.out_proj(context)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "KeBdW1zyGEH3"
      },
      "outputs": [],
      "source": [
        "mqa = MultiQueryAttention(d_model, n_heads).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kGt9m6-N6Zkc",
        "outputId": "94357c9b-5200-4f3d-85a3-fd7fc911a450"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([8, 1024, 768])"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mqa(x).shape # (batch-méret, szekvencia hossz, beágyazás méret)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sguUj-Ql6aAC"
      },
      "source": [
        "# Csoportosított Lekérdezéses Figyelem (Grouped-Query Attention, GQA)\n",
        "\n",
        "Ainslie, Joshua, James Lee-Thorp, Michiel de Jong, Yury Zemlyanskiy, Federico Lebrón, and Sumit Sanghai. “GQA: Training Generalized Multi-Query Transformer Models from Multi-Head Checkpoints.” arXiv, December 23, 2023. https://doi.org/10.48550/arXiv.2305.13245.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MZi-jdzPjdlZ"
      },
      "source": [
        "A csoportos vagy csoportosított lekérdezéses figyelem (grouped-query attention, GQA) az MQA általánosítása, amely köztes számú - azaz egynél több, de a lekérdező fejek számánál kevesebb - kulcs-érték fejet használ. Kimutatható, hogy a továbbtanított GQA közel azonos minőséget ér el, mint a többfejü figyelem, miközben a számítási sebessége összemérhető az MQA-val. A GQA a következőképpen írható fel:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "137XkGZojdm2"
      },
      "source": [
        "$$\n",
        "\\begin{array}{r}\n",
        "\\text { MultiFej }\\left(\\mathbf{X}_Q, \\mathbf{X}_K, \\mathbf{X}_V\\right)=\\text { Konkat }\\left(\\mathrm{fej}_1, \\ldots, \\mathrm{fej}_{\\mathrm{h}}\\right) \\mathbf{W}^O \\\\\n",
        "\\mathrm{fej}_i=\\text { Figyelem }\\left(\\mathbf{X}_Q \\mathbf{W}_i^Q, \\mathbf{X}_K \\mathbf{W}_{g(i)}^K, \\mathbf{X}_V \\mathbf{W}_{g(i)}^V\\right)\n",
        "\\end{array}\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iwqxmog9jqyW"
      },
      "source": [
        "Ennél a figyelem típusnál a figyelem fejek indexeit felosztjuk $m$ elemü csoportokra, és definiáljuk a $g(i)$ függvényt a következőképpen:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8N992dSLz1xM"
      },
      "source": [
        "$$\n",
        "g(i) =\\left\\lfloor\\frac{i}{m}\\right\\rfloor\n",
        "$$\n",
        "\n",
        "$$\\therefore$$\n",
        "$$\n",
        "0 = g(0)=g(1)=\\cdots=g(m-1)\n",
        "$$\n",
        "$$\n",
        "1 = g(m)=g(m+1)=\\cdots=g(2m-1)\n",
        "$$\n",
        "$$\n",
        "\\vdots\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LvvAZ4RUzZU8"
      },
      "source": [
        "A $\\mathbf{W}_i^Q \\in \\mathbb{R}^{d \\times d_k}$ az $i$-edik fej lekérdezéséhez tartozó súlymátrix, $\\mathbf{W}_{g(i)}^K \\in \\mathbb{R}^{d \\times d_k}$ és $\\mathbf{W}_{g(i)}^V \\in \\mathbb{R}^{d \\times d_{k, v}}$ a kulcs és érték leképezésekhez tartozó súlymátrixok, amelyek a $g(i)$ hozzárendelő függvény alapján meghatározott csoportonként közösek. Végül, $\\mathbf{W}^O \\in \\mathbb{R}^{h d_v \\times d}$ a kimeneti leképezéshez tartozó mátrix. Mindegyik figyelemfej esetén $d_k=d_v=\\frac{d}{h}$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "OOnr3eZE6bd5"
      },
      "outputs": [],
      "source": [
        "class GroupedQueryAttention(nn.Module):\n",
        "    def __init__(self, d_model: int, h: int, n_groups: int, qkv_bias:bool=False):\n",
        "        super().__init__()\n",
        "\n",
        "        assert d_model % h == 0, \"d_model is indivisible by n_heads\"\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.h = h\n",
        "        self.d_k = self.d_v = d_model // h\n",
        "\n",
        "        self.g = n_groups\n",
        "        self.g_size = h // n_groups\n",
        "\n",
        "        self.q_proj = nn.Linear(d_model, self.h * self.d_k, bias = qkv_bias)\n",
        "        self.k_proj = nn.Linear(d_model, self.g * self.d_k, bias = qkv_bias)\n",
        "        self.v_proj = nn.Linear(d_model, self.g * self.d_v, bias = qkv_bias)\n",
        "\n",
        "        self.out_proj = nn.Linear(self.h * self.d_v, d_model)\n",
        "\n",
        "    def forward(self, x: torch.Tensor):\n",
        "\n",
        "        b, t, d  = x.shape\n",
        "\n",
        "        q = self.q_proj(x).view(b, self.h, t, self.d_k)\n",
        "        k = self.k_proj(x).view(b, self.g, t, self.d_k)\n",
        "        v = self.v_proj(x).view(b, self.g, t, self.d_v)\n",
        "\n",
        "        k = k.repeat_interleave(self.g_size, dim=1)\n",
        "        v = v.repeat_interleave(self.g_size, dim=1)\n",
        "\n",
        "        # (b, h, t, t) = (b,  h, t, d_k) x (b, h, d_k, t)\n",
        "        attn_scores = torch.matmul(q, k.transpose(2, 3)) / math.sqrt(self.d_k)\n",
        "\n",
        "        attn_weights = F.softmax(attn_scores, dim=-1)\n",
        "\n",
        "        # (b, t, h, d_v) <- (b, h, t, d_v) = (b, h, t, t) x (b, h, t, d_v)\n",
        "        context = torch.matmul(attn_weights, v).transpose(1, 2).contiguous()\n",
        "\n",
        "        context = context.view(batch_size, t, self.d_model)\n",
        "\n",
        "        return self.out_proj(context)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "I18fgWhZ6b44"
      },
      "outputs": [],
      "source": [
        "gqa = GroupedQueryAttention(d_model, n_heads, 2).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tct5MNBb6b7t",
        "outputId": "86668d25-2b35-4ab1-d6ee-ca3ff2a45c80"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([8, 1024, 768])"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "gqa(x).shape # (batch-méret, szekvencia hossz, beágyazás méret)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vbjmkJxI6cO0"
      },
      "source": [
        "# Többfejű Látens Figyelem (Multi-head Latent Attention, MLA)\n",
        "\n",
        "DeepSeek-AI, Aixin Liu, Bei Feng, Bin Wang, Bingxuan Wang, Bo Liu, Chenggang Zhao, et al. “DeepSeek-V2: A Strong, Economical, and Efficient Mixture-of-Experts Language Model.” arXiv, June 19, 2024. https://doi.org/10.48550/arXiv.2405.04434.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rM16JLo3j_b7"
      },
      "source": [
        "A modelleknek jelentős memóriaigénye van inferencia során is, különösen a nagy nyelvi modellek esetében, ahol a szekvencia hossza és a modell mérete (a paramétereinek száma) nagy. Az inferencia gyorsítása érdekében minden kulcsot és értéket el szoktak tárolni a gyorsítótárban, hogy ne kelljen újraszámolni óket minden egyes lépésben [33, 34]. Ez egy implementációs technika, amit **kulcs-érték gyorsítótár**nak (key-value cache, KV cache) neveznek. Az MHA esetén a modellnek minden tokenhez $2 h d_h l$ elemet kell a gyorsítótárban tárolnia (ahol $l$ a rétegek száma), amely korlátozza a maximális minibatch-méretet és a feldolgozható szekvenciahosszt."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hb6dDYOqj_eN"
      },
      "source": [
        "A többfejü látens figyelem (multi-head latent attention, MLA) alacsony rangú együttes tömörítést (low-rank joint compression) alkalmaz a kulcsra és értékre, hogy a KV cache mérete csökkenjen."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XMxVBdrxoXQR"
      },
      "source": [
        "Ha $\\mathbf{X} = [\\mathbf{h}_1; \\mathbf{h}_2; \\dots; \\mathbf{h}_t] \\in \\mathbb{R}^{t \\times d}$ a bemeneti szekvencia beágyazásainak mátrixa, akkor $\\mathbf{h}_t \\in \\mathbb{R}^d$ a bemeneti szekvencia $t$-edik elemének beágyazása. Mint láttuk, az MHA első lépésben előállítja a $\\mathbf{q}_t, \\mathbf{k}_t, \\mathbf{v}_t \\in \\mathbb{R}^{d_h n_h}$ reprezentációkat az alábbi három mátrix segítségével: $\\mathbf{W}^Q, \\mathbf{W}^K, \\mathbf{W}^V \\in \\mathbb{R}^{d_h n_h \\times d}$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tMgK3X82kRJB"
      },
      "source": [
        "$$\n",
        "\\mathbf{q}_t =\\mathbf{W}^Q \\mathbf{h}_t\n",
        "$$\n",
        "$$\n",
        "\\mathbf{k}_t =\\mathbf{W}^K \\mathbf{h}_t\n",
        "$$\n",
        "$$\n",
        "\\mathbf{v}_t =\\mathbf{W}^V \\mathbf{h}_t\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eRrMRRUumdno"
      },
      "source": [
        "Az MLA lényege, hogy kulcsokban és értékekben alacsony rangú faktorizációt valósítanak meg, jelen esetben két mátrixra osztják fel. Először, egy alacsonyabb dimenziójú (kompresszált) mátrix kerül előállításra a bemenetből, ami a gyorsítótárban kerül tárolásra. Majd a figyelem számításához ezeket a tömörített reprezentációkat visszaalakítják az eredeti dimenzióra egy másik mátrix segítségével."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mbxZGOXmdp-"
      },
      "source": [
        "Mivel az $\\mathbf{X} \\in \\mathbb{R}^{t \\times d}$ bemeneti mátrix ugyanaz a kulcsra és az értékre, ezért a fentebbi három egyenletből két egyenletet átrendezik az alábbi módon:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WmyWpnLzmdr_"
      },
      "source": [
        "$$\n",
        "\\begin{aligned}\n",
        "\\mathbf{c}_t^{K V} & =\\mathbf{W}^{D K V} \\mathbf{h}_t, \\\\\n",
        "\\mathbf{k}_t^C & =\\mathbf{W}^{U K} \\mathbf{c}_t^{K V}, \\\\\n",
        "\\mathbf{v}_t^C & =\\mathbf{W}^{U V} \\mathbf{c}_t^{K V},\n",
        "\\end{aligned}\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZC_N95t5m_zh"
      },
      "source": [
        "ahol $\\mathbf{c}_t^{K V} \\in \\mathbb{R}^{d_c}$ a tömörített látens vektor kulcsra és értékre, $d_c\\left(\\ll d_h n_h\\right)$ a tömörítés dimenzióját adja, $\\mathbf{W}^{D K V} \\in \\mathbb{R}^{d_c \\times d}$ a dimenziócsökkentó mátrix és $\\mathbf{W}^{U K}, \\mathbf{W}^{U V} \\in \\mathbb{R}^{d_h n_h \\times d_c}$ a dimenziónövelő mátrixok."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oySuXOsqo6w0"
      },
      "source": [
        "A kulcs és érték szétbontása azért fontos, mert az inferencia során a $\\mathbf{c}_t^{K V}$-t gyorsítótárban tárolják, ezáltal a KV cache mérete $d_c l$ elem lesz. Továbbá, a lekérdezés mátrixot is szétválasztják tanítás során a memória csökkentése érdekében, bár ez nem csökkenti a KV cache méretét."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "GUcchmSTargI"
      },
      "outputs": [],
      "source": [
        "class MultiHeadLatentAttention(nn.Module):\n",
        "    def __init__(self, d_model: int, n_h: int, d_cq: int = 12, d_c: int = 4):\n",
        "        super().__init__()\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.n_h = n_h          # n_heads\n",
        "        self.d_c = d_c          # d_c (<< d_h * n_h)\n",
        "        self.d_cq = d_cq        # d_c' (<< d_h * n_h)\n",
        "\n",
        "        self.d_h = d_model // n_heads\n",
        "\n",
        "        # down-projection matrices\n",
        "        self.w_dq = nn.Linear(d_model, d_cq)\n",
        "        self.w_dkv = nn.Linear(d_model, d_c)\n",
        "\n",
        "        # up-projection matrices\n",
        "        self.w_uq = nn.Linear(d_cq, n_h * self.d_h)\n",
        "        self.w_uk = nn.Linear(d_c, n_h * self.d_h)\n",
        "        self.w_uv = nn.Linear(d_c, n_h * self.d_h)\n",
        "\n",
        "        self.w_o = nn.Linear(n_heads * self.d_h, d_model) # out proj\n",
        "\n",
        "    def forward(self, x: torch.Tensor):\n",
        "\n",
        "        b, t, d_model = x.shape\n",
        "\n",
        "        # compression\n",
        "        c_q = self.w_dq(x)     # (b, t, d_c')\n",
        "        c_kv = self.w_dkv(x)   # (b, t, d_c)\n",
        "\n",
        "        # decompression\n",
        "        q_c = self.w_uq(c_q).view(b, self.n_h, t, self.d_h)\n",
        "        k_c = self.w_uk(c_kv).view(b, self.n_h, t, self.d_h)\n",
        "        v_c = self.w_uv(c_kv).view(b, self.n_h, t, self.d_h)\n",
        "\n",
        "        # (b, h, t, t) = (b, h, t, d_h) x (b, h, d_h, t)\n",
        "        attn_scores = torch.matmul(q_c, k_c.transpose(2, 3)) / math.sqrt(self.d_h)\n",
        "\n",
        "        attn_weight = torch.softmax(attn_scores, dim=-1)\n",
        "\n",
        "        # (b, t, h, d_h) <- (b, h, t, d_h) = (b, h, t, t) x (b, h, t, d_h)\n",
        "        context = torch.matmul(attn_weight, v_c).transpose(1,2).contiguous()\n",
        "\n",
        "        context = context.view(b, t, self.d_model)\n",
        "\n",
        "        return self.w_o(context)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "Q9mmaI4JbkN-"
      },
      "outputs": [],
      "source": [
        "mla = MultiHeadLatentAttention(d_model, n_heads, 2).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ow6gf8tbrJy",
        "outputId": "b33d0bff-0e62-4b39-b78d-b5bcc0e55c0c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([8, 1024, 768])"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mla(x).shape # (batch_size, num_tokens, d_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k5BL6mirr6De"
      },
      "source": [
        "# Gyorsasági Összehasonlítás (Speed Comparison)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "r-vX8ABjsZMJ"
      },
      "outputs": [],
      "source": [
        "attention_fns = {\n",
        "    \"mha\": mha,\n",
        "    \"mqa\": mqa,\n",
        "    \"gqa\": gqa,\n",
        "    \"mla\": mla\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "A6CmvZbkr7nO"
      },
      "outputs": [],
      "source": [
        "def time_pytorch_function(func, *input, num_repeats=1_000):\n",
        "\n",
        "    start = torch.cuda.Event(enable_timing=True)\n",
        "    end = torch.cuda.Event(enable_timing=True)\n",
        "\n",
        "    for _ in range(5):\n",
        "        func(*input)\n",
        "    torch.cuda.synchronize()\n",
        "\n",
        "    times = []\n",
        "    for _ in range(num_repeats):\n",
        "        start.record()\n",
        "        func(*input)\n",
        "        end.record()\n",
        "        torch.cuda.synchronize()\n",
        "        times.append(start.elapsed_time(end))\n",
        "\n",
        "    return np.mean(times), np.std(times)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "collapsed": true,
        "id": "2uwjPn6lsVkK"
      },
      "outputs": [],
      "source": [
        "stats = [time_pytorch_function(fn, x, num_repeats=100) for fn in attention_fns.values()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "_ixSzqpasWUC"
      },
      "outputs": [],
      "source": [
        "execution_means = [stat[0] for stat in stats]\n",
        "execution_stds = [stat[1] for stat in stats]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "LijMU8udsGug"
      },
      "outputs": [],
      "source": [
        "def plot_execution_times(functions, execution_means, execution_stds):\n",
        "\n",
        "    fig, ax = plt.subplots()\n",
        "    bars = ax.bar(functions.keys(), execution_means, yerr=execution_stds, capsize=5, error_kw={'ecolor': 'grey'})\n",
        "\n",
        "    plt.ylabel(\"Execution time (ms)\")\n",
        "    plt.xticks(rotation=45, ha=\"right\")\n",
        "\n",
        "    max_execution_time = max(execution_means)\n",
        "    upper_ylim = max_execution_time + 0.4 * max_execution_time\n",
        "    plt.ylim(0, upper_ylim)\n",
        "\n",
        "    for bar in bars:\n",
        "        yval = bar.get_height()\n",
        "        plt.text(bar.get_x() + bar.get_width()/2, yval + (0.05 * upper_ylim), round(yval, 2), ha=\"center\", va=\"bottom\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "TqdDxYOmsSyy",
        "outputId": "e005fd69-6bbc-4240-8346-6fb1a6946cd6"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plot_execution_times(attention_fns, execution_means, execution_stds)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
